{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57891,"databundleVersionId":7056235,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-20T21:16:46.091117Z","iopub.execute_input":"2023-11-20T21:16:46.091496Z","iopub.status.idle":"2023-11-20T21:16:46.102636Z","shell.execute_reply.started":"2023-11-20T21:16:46.091466Z","shell.execute_reply":"2023-11-20T21:16:46.101662Z"},"trusted":true},"execution_count":334,"outputs":[{"name":"stdout","text":"/kaggle/input/optiver-trading-at-the-close/public_timeseries_testing_util.py\n/kaggle/input/optiver-trading-at-the-close/train.csv\n/kaggle/input/optiver-trading-at-the-close/example_test_files/sample_submission.csv\n/kaggle/input/optiver-trading-at-the-close/example_test_files/revealed_targets.csv\n/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv\n/kaggle/input/optiver-trading-at-the-close/optiver2023/competition.cpython-310-x86_64-linux-gnu.so\n/kaggle/input/optiver-trading-at-the-close/optiver2023/__init__.py\n","output_type":"stream"}]},{"cell_type":"code","source":"#Instal new version of Tensorflow\n#!pip3 install --upgrade tensorflow==2.12.0","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:16:46.133090Z","iopub.execute_input":"2023-11-20T21:16:46.133390Z","iopub.status.idle":"2023-11-20T21:16:46.138360Z","shell.execute_reply.started":"2023-11-20T21:16:46.133364Z","shell.execute_reply":"2023-11-20T21:16:46.137477Z"},"trusted":true},"execution_count":335,"outputs":[]},{"cell_type":"code","source":"import random\nfrom datetime import datetime\nimport time\nimport resource\nimport pickle\nimport os\nimport pdb\n\n\nimport numpy as np\nimport pandas as pd\nimport keras\nfrom scipy.interpolate import pchip_interpolate\n\nimport tensorflow as tf\n#import tensorflow.keras\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Input, Dense, Dropout\n#In old version of Tensorflow 2.8.0\n#from tensorflow.keras.optimizers import Adam\n#In new version of Tensorflow 2.12.0, please use legacy to import Adam\nfrom tensorflow.keras.optimizers.legacy import Adam\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.regularizers import l2\nimport tensorflow.keras.backend as K\n#from keras import backend as K\n\nimport plotly\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfrom IPython.display import clear_output, display, HTML\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# originally built on old TensorFlow and Keras which didn't support eager execution\ntf.compat.v1.disable_eager_execution()\n#tf.compat.v1.disable_v2_behavior()\n#tf.compat.v1.enable_eager_execution()\n\n# set seeds for reproducibility\n# np.random.uniform(0,10000) 4465\nrandom.seed(4465)\nnp.random.seed(4465)\ntf.random.set_seed(4465)\n\nprint(\"TensorFlow %s\" % tf.__version__)\nprint(\"Keras %s\" % keras.__version__)\nprint(\"plotly %s\" % plotly.__version__)\nprint(\"pandas %s\" % pd.__version__)\nprint(\"numpy %s\" % np.__version__)\n\n# If model save directory isn't made yet, make it\nif not os.path.exists('model_output'):\n    os.makedirs('model_output')\nif not os.path.exists('model_output/trading'):\n    os.makedirs('model_output/trading')","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:16:46.184285Z","iopub.execute_input":"2023-11-20T21:16:46.184593Z","iopub.status.idle":"2023-11-20T21:16:46.196829Z","shell.execute_reply.started":"2023-11-20T21:16:46.184565Z","shell.execute_reply":"2023-11-20T21:16:46.195789Z"},"trusted":true},"execution_count":336,"outputs":[{"name":"stdout","text":"TensorFlow 2.12.0\nKeras 2.12.0\nplotly 5.15.0\npandas 2.0.3\nnumpy 1.23.5\n","output_type":"stream"}]},{"cell_type":"code","source":"def sizeof_fmt(num, suffix='B'):\n    \"\"\"given memory as int format as memory units eg KB\"\"\"\n    for unit in ['', 'K', 'M', 'G', 'T', 'P', 'E', 'Z']:\n        if abs(num) < 1024.0:\n            return \"%3.1f %s%s\" % (num, unit, suffix)\n        num /= 1024.0\n    return \"%.1f %s%s\" % (num, 'Y', suffix)\n\ndef memusage():\n    \"\"\"print memory usage\"\"\"\n    return sizeof_fmt(int(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss))\n\nmemusage()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:16:46.233902Z","iopub.execute_input":"2023-11-20T21:16:46.234166Z","iopub.status.idle":"2023-11-20T21:16:46.243395Z","shell.execute_reply.started":"2023-11-20T21:16:46.234142Z","shell.execute_reply":"2023-11-20T21:16:46.242430Z"},"trusted":true},"execution_count":337,"outputs":[{"execution_count":337,"output_type":"execute_result","data":{"text/plain":"'3.8 MB'"},"metadata":{}}]},{"cell_type":"code","source":"def make_figure(*series, title=\"\", xtitle=\"\", ytitle=\"\"):\n    fig = go.Figure()\n    series=list(series)\n    x = series.pop(0)\n    for s in series:\n        fig.add_trace(go.Scatter(y=s, x=x))\n    fig.update_layout(\n        title= dict(text=title,\n                    x=0.5,\n                    xanchor='center'),\n        xaxis=dict(\n            title=xtitle,\n            linecolor='black',\n            linewidth=1,\n            mirror=True\n        ),\n        yaxis=dict(\n            title=ytitle,\n            linecolor='black',\n            linewidth=1,\n            mirror=True\n        ),\n        showlegend=False\n    )\n\n    return fig.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:16:46.330710Z","iopub.execute_input":"2023-11-20T21:16:46.330993Z","iopub.status.idle":"2023-11-20T21:16:46.337815Z","shell.execute_reply.started":"2023-11-20T21:16:46.330971Z","shell.execute_reply":"2023-11-20T21:16:46.336920Z"},"trusted":true},"execution_count":338,"outputs":[]},{"cell_type":"code","source":"stock_series = []\nprob_memory = []\n\namplifier=1000\ndate=478\nstock=46\n#be cautious when setting dt. dt is inverse proportional to learning time dt=1 means no optimization\ndt=1\n\n#filename=\"IndexWap_day231.csv\"\n#excelfilereader=pd.read_csv(r'/content/kaggle_optiver_data/IndexWap_day231.csv', header=None)\n#data = excelfilereader.iloc[0,:].values.tolist()\n#data = excelfilereader.iloc[0,:]*1000\n\n#excelfilereader=pd.read_csv(r'/kaggle/input/optiver-trading-at-the-close/train.csv')\n\nexcelfilereader=pd.read_csv(r'/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv')\n\ndef Data_input(test,stock,date,amplifier,dt=1):\n    data_sub=test[test['stock_id']==stock]\n    data_sub2=data_sub[data_sub['date_id']==date]\n    data=pd.DataFrame(data_sub2,columns=['wap'])\n    data = data.values.tolist()\n    data=np.squeeze(data)\n    data=data*amplifier\n    stock_series=data\n    time_series=range(0,data.shape[0])\n    df = pd.DataFrame({'dateindex': time_series, 'stock': stock_series})\n    x=df['dateindex']\n    y=df['stock']\n    x_sub = np.linspace(min(x), max(x), num=int(df.shape[0]/dt))\n    y_sub = pchip_interpolate(x, y, x_sub)\n    df_new = pd.DataFrame({'dateindex': x_sub, 'stock': y_sub})\n    return df_new\n\ndf_new=Data_input(excelfilereader,stock,date,amplifier)\n\nmake_figure(df_new['dateindex'], df_new['stock'],\n            title=\"Stock {} price at date {}\".format(int(stock), int(date)),\n            xtitle='Timesteps',\n            ytitle='Value'\n           )\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:16:46.411813Z","iopub.execute_input":"2023-11-20T21:16:46.412372Z","iopub.status.idle":"2023-11-20T21:16:46.523222Z","shell.execute_reply.started":"2023-11-20T21:16:46.412348Z","shell.execute_reply":"2023-11-20T21:16:46.522165Z"},"trusted":true},"execution_count":339,"outputs":[{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"0b9777ca-7fc3-4d86-9cce-c9e9365a07e6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0b9777ca-7fc3-4d86-9cce-c9e9365a07e6\")) {                    Plotly.newPlot(                        \"0b9777ca-7fc3-4d86-9cce-c9e9365a07e6\",                        [{\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0,51.0,52.0,53.0,54.0],\"y\":[1000.0,999.8430000000001,999.771,999.479,999.338,999.4150000000001,999.9259999999999,1000.5269999999999,1000.777,1000.8649999999999,1001.1099999999999,1001.001,1000.886,1001.2149999999999,1001.1920000000001,1000.958,1000.043,999.829,1000.2260000000001,1000.2390000000001,1000.6330000000002,1000.6569999999999,1000.7090000000001,1000.556,1000.4599999999999,1000.1949999999999,999.8979999999999,999.859,1000.4980000000002,1000.4599999999999,999.95,1000.036,1000.437,1000.4399999999999,1000.464,1000.2009999999999,1000.248,1000.2599999999999,1000.1899999999999,1000.2059999999999,1000.284,1000.4599999999999,1000.665,1000.675,1000.839,1000.8399999999999,1000.5489999999999,1000.499,1000.1880000000001,1000.276,1000.3530000000001,1000.3100000000001,1000.3470000000001,1000.383,1000.2800000000001],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Stock 46 price at date 478\",\"x\":0.5,\"xanchor\":\"center\"},\"xaxis\":{\"title\":{\"text\":\"Timesteps\"},\"linecolor\":\"black\",\"linewidth\":1,\"mirror\":true},\"yaxis\":{\"title\":{\"text\":\"Value\"},\"linecolor\":\"black\",\"linewidth\":1,\"mirror\":true},\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('0b9777ca-7fc3-4d86-9cce-c9e9365a07e6');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"code","source":"index_1=[0,6,12,18,24,30,36,42,48,54]\nindex_2=[1,7,13,19,25,31,37,43,49]\nindex_3=[2,8,14,20,26,32,38,44,50]\nindex_4=[3,9,15,21,27,33,39,45,51]\nindex_5=[4,10,16,22,28,34,40,46,52]\nindex_6=[5,11,17,23,29,35,41,47,53]\nindex_list=[index_1,index_2,index_3,index_4,index_5, index_6]\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:16:46.525185Z","iopub.execute_input":"2023-11-20T21:16:46.525722Z","iopub.status.idle":"2023-11-20T21:16:46.532293Z","shell.execute_reply.started":"2023-11-20T21:16:46.525688Z","shell.execute_reply":"2023-11-20T21:16:46.531324Z"},"trusted":true},"execution_count":340,"outputs":[]},{"cell_type":"code","source":"def indexWAP(data, date, t):\n    coefficient = [0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.002,\n                   0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004, 0.002, 0.002, 0.004, 0.002,\n                   0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004, 0.004, 0.004, 0.006, 0.002, 0.002, 0.04,\n                   0.002, 0.002, 0.004, 0.04, 0.002, 0.001, 0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002,\n                   0.006, 0.004, 0.006, 0.004, 0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004,\n                   0.002, 0.004, 0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n                   0.02, 0.004, 0.006, 0.002, 0.02, 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02, 0.006, 0.001, 0.002,\n                   0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002, 0.004, 0.006, 0.006, 0.001, 0.04,\n                   0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002, 0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008,\n                   0.006, 0.004, 0.002, 0.006, 0.002, 0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008,\n                   0.006, 0.008, 0.002, 0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001,\n                   0.002, 0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002, 0.04,\n                   0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02, 0.004, 0.002, 0.006, 0.02, 0.001, 0.002, 0.006,\n                   0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04, 0.002, 0.008, 0.002, 0.004, 0.001,\n                   0.004, 0.006, 0.004]\n    date_sub = data.loc[(data[\"date_id\"] == date) & (data[\"seconds_in_bucket\"] == t)]\n    stk_id = pd.DataFrame(date_sub, columns=[\"stock_id\"])\n    wap = pd.DataFrame(date_sub, columns=[\"wap\"])\n    stk_id_arr = np.array(stk_id).reshape(-1)\n\n    missing_elemnts = [item for item in range(stk_id_arr[0], 200) if item not in stk_id_arr]\n    missing_elemnts_arr = np.array(missing_elemnts).reshape(-1)\n    list_coefficient = coefficient\n    for i in sorted(missing_elemnts_arr, reverse=True):\n        list_coefficient.pop(i)\n\n    norm = [float(i) / sum(list_coefficient) for i in list_coefficient]\n    stock_index = np.dot(norm, wap)\n    return (np.array([stock_index]).item())\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:16:46.533221Z","iopub.execute_input":"2023-11-20T21:16:46.533453Z","iopub.status.idle":"2023-11-20T21:16:46.550536Z","shell.execute_reply.started":"2023-11-20T21:16:46.533432Z","shell.execute_reply":"2023-11-20T21:16:46.549611Z"},"trusted":true},"execution_count":341,"outputs":[]},{"cell_type":"code","source":"def Index_Calc(test,date):\n    time_arr = np.arange(0, 550, 10)\n    date_0 = test.loc[(test[\"date_id\"] == date)]\n\n    index = []\n\n    for i in time_arr:\n        index.append(indexWAP(date_0, date, i))\n    index=np.squeeze(index)\n    index=index*amplifier\n    df_index = pd.DataFrame({'dateindex': x_sub, 'stock': index})\n    return df_index\n\n#df_index=Index_Calc(date)\n#make_figure(df_index['dateindex'], df_index['stock'],\n#            title=\"Index at date {}\".format(int(date)),\n#            xtitle='Timesteps',\n#            ytitle='Value'\n#           )\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:16:46.552166Z","iopub.execute_input":"2023-11-20T21:16:46.552432Z","iopub.status.idle":"2023-11-20T21:16:46.568091Z","shell.execute_reply.started":"2023-11-20T21:16:46.552403Z","shell.execute_reply":"2023-11-20T21:16:46.567360Z"},"trusted":true},"execution_count":342,"outputs":[]},{"cell_type":"code","source":"def user_gen(df,start_trend=amplifier):\n    t=0\n    trend_index = start_trend\n    while t<=(df.shape[0]):\n        stock_price= df['stock'][t]\n        yield(t, stock_price, trend_index)\n        t+=1\n\ndef user_gen_dt(df,dt=1,start_trend=amplifier):\n    t=0\n    trend_index = start_trend\n    x=df['dateindex']\n    y=df['stock']\n    x_sub = np.linspace(min(x), max(x), num=int(df.shape[0]/dt))\n  #print(np.shape(x_sub))\n    y_sub = pchip_interpolate(x, y, x_sub)\n  #print(np.shape(y_sub))\n    while t<=int(len(x_sub)/dt):\n        stock_price= y_sub[t]\n        yield(t, stock_price, trend_index)\n        t+=dt\n\ndef user_sub(df,index_sub,start_trend=amplifier):\n    t=0\n    trend_index = start_trend\n    x=range(len(index_sub))\n    y=[]\n    #x=df['dateindex'][index_sub]\n    y=df['stock'][index_sub]\n    for i in range(len(index_sub)):\n        y[i]=df['stock'][index_sub[i]]\n    while t<=int(len(x)):\n        stock_price= y[t]\n        yield(t, stock_price, trend_index)\n        t+=1","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:16:46.574029Z","iopub.execute_input":"2023-11-20T21:16:46.574268Z","iopub.status.idle":"2023-11-20T21:16:46.583806Z","shell.execute_reply.started":"2023-11-20T21:16:46.574247Z","shell.execute_reply":"2023-11-20T21:16:46.582723Z"},"trusted":true},"execution_count":343,"outputs":[]},{"cell_type":"code","source":"def market_gen(gen, lag=1):\n\n    buffer = []\n    diffbuffer = []\n\n\n    # fill buffer\n    dt, last, trend = next(gen)\n    for i in range(lag):\n        prev = last\n        dt, last, trend = next(gen)\n        buffer.append(last-trend)\n        diffbuffer.append(last-prev)\n\n    # yield first group of lag vals and diffs\n    yield buffer+diffbuffer\n\n    while(True):\n        prev = last\n        dt, last, trend = next(gen)\n        buffer.pop(0)\n        buffer.append(last-trend)\n        diffbuffer.pop(0)\n        diffbuffer.append(last-prev)\n        yield buffer+diffbuffer\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:16:46.622711Z","iopub.execute_input":"2023-11-20T21:16:46.622982Z","iopub.status.idle":"2023-11-20T21:16:46.629547Z","shell.execute_reply.started":"2023-11-20T21:16:46.622958Z","shell.execute_reply":"2023-11-20T21:16:46.628598Z"},"trusted":true},"execution_count":344,"outputs":[]},{"cell_type":"code","source":"class Market:\n    \"\"\"Follows OpenAI gym environment convention basically\n    init with generator and number of stocks\n    reset() - generate and return first state\n    step() - generate next state and reward\n    \"\"\"\n    def __init__(self, gen, lag=16, nstocks=1, episode_length=300):\n        self.genfunc = gen\n        self.nstocks = nstocks\n        self.episode_length = episode_length\n        self.t = 0\n        self.total_reward = 0\n        self.lag = lag\n        self.observation_space = np.asarray([1] * nstocks * lag * 2,)\n        self.state_size = nstocks * lag * 2\n        self.action_size = 2\n\n    def reset(self):\n        self.t = 0\n        self.total_reward = 0\n        self.gen = [self.genfunc() for _ in range(self.nstocks)]\n        self.state=[next(g) for g in self.gen]\n        self.state = np.asarray([s for s in self.state])\n        return self.state\n\n    def render(self):\n        print(self.state[0, nstocks-1])\n\n    def step(self, action):\n        action = np.asarray([action])\n        try:\n            self.state=[next(g) for g in self.gen]\n        except StopIteration:\n            return print(\"generator failed.\\n\")\n        \n        self.state = np.asarray([s for s in self.state])\n        # last element is most recent change\n        stock_delta = np.asarray([s[-1] for s in self.state])\n        # element at lag-1 is most recent deviation\n        market_price = np.asarray([s[self.lag-1]+100 for s in self.state])\n        # map actions 0 1 2 to positions -1, 0, 1\n        position = action - 1\n        reward = position @ stock_delta\n        self.total_reward += reward\n        self.t += 1\n        done = True if self.episode_length and self.t >= self.episode_length else False\n        # state, reward, done, info\n        return self.state, reward, done, market_price\n\n    def close(self):\n        pass\n\n\n#env = Market(user_gen_dt(df,0.1), lag=1, nstocks=1, episode_length=10)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:16:46.669434Z","iopub.execute_input":"2023-11-20T21:16:46.669718Z","iopub.status.idle":"2023-11-20T21:16:46.681292Z","shell.execute_reply.started":"2023-11-20T21:16:46.669696Z","shell.execute_reply":"2023-11-20T21:16:46.680320Z"},"trusted":true},"execution_count":345,"outputs":[]},{"cell_type":"code","source":"DISCOUNT_RATE = 0\n# WIN_REWARD = 10\nEPSILON_DECAY = 0.995\nSAMPLE_SIZE = 256\nRENDER = False\nOUTPUT_DIR = 'model_output/trading/'\n\nclass DQN_Agent:\n    def __init__(self, state_size, action_size, filename=\"dqn\",\n                 discount_rate=DISCOUNT_RATE,\n                 learning_rate=0.001,\n                 epsilon=1.0,\n                 epsilon_decay=EPSILON_DECAY,\n                 epsilon_min=0.01):\n\n        self.state_size = state_size\n        self.action_size = action_size\n        self.filename = filename\n        self.discount_rate = discount_rate\n        self.epsilon = epsilon\n        self.epsilon_decay = epsilon_decay\n        self.epsilon_min = epsilon_min\n        self.learning_rate = learning_rate\n\n        self.model = self.build_model()\n        self.memory = pd.DataFrame(columns=[\"state\", \"action\", \"next_state\",\n                                            \"reward\", \"done\"])\n        self.memory_size = 100000\n        self.results = []\n        self.train_batch_size = 1\n        self.timestep = 0\n        self.save_interval = 10\n\n    def build_model(self,\n                    n_hidden_layers=2,\n                    hidden_layer_size=16,\n                    activation='relu',\n                    reg_penalty=0.001,\n                    dropout=0.0675,\n                    verbose=True\n                   ):\n        \"\"\"return keras NN model per inputs\n        input is a state - array of size state_size\n        output is an array of action values - array of size action_size\n        \"\"\"\n\n        inputs = Input(shape=(self.state_size,), name=\"Input\")\n        last_layer = inputs\n\n        for i in range(n_hidden_layers):\n            if verbose:\n                formatstr = \"layer %d size %d, %s, reg_penalty %.8f, dropout %.3f\"\n                print(formatstr % (i + 1,\n                                   hidden_layer_size,\n                                   activation,\n                                   reg_penalty,\n                                   dropout))\n            # add dropout, but not on inputs, only between hidden layers\n            if i and dropout:\n                last_layer = Dropout(dropout, name=\"Dropout%02d\" % i)(last_layer)\n\n            last_layer = Dense(units=hidden_layer_size,\n                               activation=activation,\n                               kernel_initializer=glorot_uniform(),\n                               kernel_regularizer=l2(reg_penalty),\n                               name=\"Dense%02d\" % i)(last_layer)\n\n        outputs = Dense(self.action_size, activation='linear', name=\"Output\")(last_layer)\n\n        #model = Model(inputs=input_layer , output=last_layer)\n        model = Model(inputs=inputs, outputs=outputs)\n\n        if verbose:\n            print(model.summary())\n\n        model.compile(loss='mse', optimizer=Adam(\n            #learning_rate=self.learning_rate\n        ))\n\n        return model\n\n    def remember(self):\n        \"\"\"store the states and rewards needed to fit the model\"\"\"\n        # append in place\n        self.memory.loc[self.memory.shape[0]] = [self.state,\n                                                 self.action,\n                                                 self.next_state,\n                                                 self.reward,\n                                                 self.done]\n\n    def train(self):\n        \"\"\"train the model on experience stored by remember\"\"\"\n\n        # need at least SAMPLE_SIZE observations\n        if self.memory.shape[0] < SAMPLE_SIZE:\n            return\n\n        # truncate memory\n        self.memory = self.memory[-self.memory_size:]\n        # sample sample_size observations from memory\n        minibatch = self.memory.sample(n=SAMPLE_SIZE)\n\n        # target is our best estimate of value of each action\n        X_fit = np.concatenate(minibatch['state'].values)\n        X_fit = X_fit.reshape((SAMPLE_SIZE, self.state_size))\n        Y_pred = self.model.predict(X_fit)\n\n        # we don't just fit model against model's own prediction, gets us nowhere\n        # we improve the target by what we learned about the action we actually took\n        # value is reward obtained + predicted value of the observed next state\n        minibatch['target_observed'] = minibatch['reward']\n        # if done, target is the reward\n        # reward by gym env is only 1 for each timestep of survival\n        # but we also added a reward of -10 on failure\n        # if not done, add discount_rate  * Q-value prediction for  observed next state\n        not_done = minibatch.loc[minibatch['done'] == False]\n        X_observed = np.concatenate(not_done['next_state'].values)\n        X_observed = X_observed.reshape((not_done.shape[0], self.state_size))\n        # run all predictions at once\n        # iterates faster but does not train after each prediction\n        y_observed_pred = np.amax(self.model.predict(X_observed), axis=1)\n        minibatch.loc[minibatch['done'] == False, 'target_observed'] \\\n            += self.discount_rate * y_observed_pred\n        # vectorized vlookup - update col specified by action with target_observed\n        np.put_along_axis(Y_pred,\n                          minibatch['action'].astype(int).values.reshape(SAMPLE_SIZE, 1),\n                          minibatch['target_observed'].values.reshape(SAMPLE_SIZE, 1),\n                          axis=1)\n        # fit model against improved target\n        # arbitrary 8 batch size to reduce variance a little and speed up fit\n        self.model.fit(X_fit, Y_pred,\n                       epochs=1,\n                       batch_size=self.train_batch_size,\n                       verbose=0)\n\n        if self.epsilon > self.epsilon_min:\n            self.epsilon *= self.epsilon_decay\n\n    def act(self, state):\n        \"\"\"pick an action using model\"\"\"\n        if np.random.rand() <= self.epsilon:\n            return random.randrange(self.action_size)\n        act_values = self.model.predict(state)\n        return np.argmax(act_values[0])\n\n    def save(self):\n        \"save agent: pickle self and use Keras native save model\"\n        fullname = \"%s%s%05d\" % (OUTPUT_DIR, self.filename, len(self.results))\n        self.model.save(\"%s.h5\" % fullname)\n        pickle.dump(self, open(\"%s.p\" % fullname, \"wb\"))\n\n    def load(filename):\n        \"load saved agent\"\n        new = pickle.load(open(\"%s.p\" % filename, \"rb\"))\n        new.model = load_model(\"%s.h5\" % filename)\n        print(\"loaded %d results, %d rows of memory, epsilon %.4f\" % (len(new.results),\n                                                                      len(new.memory),\n                                                                      new.epsilon))\n        return new\n\n    def reset(self):\n        \"\"\"reset agent for start of episode\"\"\"\n        self.timestep = 0\n        self.total_reward = 0\n\n    def increment_time(self):\n        \"\"\"increment timestep counter\"\"\"\n        self.timestep += 1\n\n    def save_score(self):\n        \"\"\"save score of each episode\"\"\"\n        self.results.append(self.total_reward)\n\n    def score_episode(self, episode_num, n_episodes):\n        \"\"\"output results and save\"\"\"\n        self.save_score()\n        avglen = min(len(self.results), self.save_interval)\n        formatstr = \"{} episode {}/{}:, score: {}, {}-episode avg: {:.1f} Memory: {}        \"\n        print(formatstr.format(time.strftime(\"%H:%M:%S\"), len(self.results),\n                               n_episodes, self.total_reward, avglen,\n                               sum(self.results[-avglen:])/avglen, memusage()),\n              end=\"\\r\", flush=False)\n\n    def run_episode(self, render=RENDER):\n        \"\"\"run a full episode\"\"\"\n        global env\n\n        self.reset()\n        self.state = env.reset()\n        self.done = False\n\n        while not self.done:\n            if render:\n                env.render()\n            self.action = self.act(self.state.reshape([1, self.state_size]))\n            self.next_state, self.reward, self.done, _ = env.step(self.action)\n            self.total_reward += self.reward\n            self.remember()\n            self.state = self.next_state\n            self.increment_time()\n\n        if render:\n            env.render()\n\n        self.train()\n\n    def rlplot(self, title='Agent Training Progress'):\n        \"\"\"plot training progress\"\"\"\n        df = pd.DataFrame({'timesteps': self.results})\n        df['avg'] = df['timesteps'].rolling(10).mean()\n\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(x=df.index,\n                                 y=df['timesteps'],\n                                 mode='markers',\n                                 name='timesteps',\n                                 marker=dict(\n                                     color='mediumblue',\n                                     size=4,\n                                 ),\n                                ))\n\n        fig.add_trace(go.Scatter(x=df.index,\n                                 y=df['avg'],\n                                 mode='lines',\n                                 line_width=3,\n                                 name='moving average'))\n\n        fig.update_layout(\n            title=dict(text=title,\n                       x=0.5,\n                       xanchor='center'),\n            xaxis=dict(\n                title=\"Episodes\",\n                linecolor='black',\n                linewidth=1,\n                mirror=True\n            ),\n            yaxis=dict(\n                title=\"Total Reward per Episode\",\n                linecolor='black',\n                linewidth=1,\n                mirror=True\n            ),\n            legend=go.layout.Legend(\n                x=0.01,\n                y=0.99,\n                traceorder=\"normal\",\n                font=dict(\n                    family=\"sans-serif\",\n                    size=12,\n                    color=\"black\"\n                ),\n                #bgcolor=\"LightSteelBlue\",\n                bordercolor=\"Black\",\n                borderwidth=1,\n            ),\n        )\n\n        return fig.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:16:46.719026Z","iopub.execute_input":"2023-11-20T21:16:46.719269Z","iopub.status.idle":"2023-11-20T21:16:46.757060Z","shell.execute_reply.started":"2023-11-20T21:16:46.719248Z","shell.execute_reply":"2023-11-20T21:16:46.756190Z"},"trusted":true},"execution_count":346,"outputs":[]},{"cell_type":"code","source":"RENDER = False\nOUTPUT_DIR = 'model_output/trading/'\n\nclass Agent:\n    \"\"\"abstract base class for agents\"\"\"\n\n    def __init__(self, state_size, action_size, filename=\"model\",\n                 *args, **kwargs):\n        self.state_size = state_size\n        self.action_size = action_size\n        self.filename = filename\n        self.timestep = 0\n        self.total_reward = 0\n        self.save_interval = 10\n\n        raise NotImplementedError\n\n    def build_model(self, *args, **kwargs):\n        \"\"\"build the relevant model\"\"\"\n        raise NotImplementedError\n\n    def reset(self):\n        \"\"\"reset agent for start of episode\"\"\"\n        self.timestep = 0\n        self.total_reward = 0\n\n    def increment_time(self):\n        \"\"\"increment timestep counter\"\"\"\n        self.timestep += 1\n\n    def remember(self, *args, **kwargs):\n        \"\"\"store the states and rewards needed to fit the model\"\"\"\n        raise NotImplementedError\n\n    def train(self, *args, **kwargs):\n        \"\"\"train the model on experience stored by remember\"\"\"\n        raise NotImplementedError\n\n    def act(self, *args, **kwargs):\n        \"\"\"pick an action using model\"\"\"\n        raise NotImplementedError\n\n    def save_score(self):\n        \"\"\"save score of each episode\"\"\"\n        self.results.append(self.total_reward)\n\n    def score_episode(self, episode_num, n_episodes):\n        \"\"\"output results and save\"\"\"\n        self.save_score()\n        avglen = min(len(self.results), self.save_interval)\n        formatstr = \"{} episode {}/{}:, score: {}, {}-episode avg: {:.1f} Memory: {}        \"\n        print(formatstr.format(time.strftime(\"%H:%M:%S\"), len(self.results),\n                               n_episodes, self.total_reward, avglen,\n                               sum(self.results[-avglen:])/avglen, memusage()),\n              end=\"\\r\", flush=False)\n\n    def run_episode(self, render=RENDER):\n        \"\"\"run a full episode\"\"\"\n        global env\n\n        self.reset()\n        self.state = env.reset()\n        self.done = False\n\n        while not self.done:\n            if render:\n                env.render()\n            self.action = self.act(self.state.reshape([1, self.state_size]))\n            self.next_state, self.reward, self.done, _ = env.step(self.action)\n            self.total_reward += self.reward\n\n            self.remember()\n            self.state = self.next_state\n            self.increment_time()\n\n        if render:\n            env.render()\n\n        self.train()\n\n    def save(self, *args, **kwargs):\n        \"\"\"save agent to disk\"\"\"\n        raise NotImplementedError\n\n    def load(*args, **kwargs):\n        \"\"\"load agent from disk\"\"\"\n        raise NotImplementedError\n\n    def view(self):\n        \"\"\"Run an episode without training, with rendering\"\"\"\n        state = env.reset()\n        state = np.reshape(state, [1, self.state_size])\n        done = False\n\n        # run an episode\n        self.timestep = 0\n        r = 0\n        while not done:\n            env.render()\n            action = self.act(state)\n            lastmarket = self.state[0, nstocks-1]\n            state, reward, done, _ = env.step(action)\n            newmarket = self.state[0, nstocks-1]\n            print(\"prev mkt: %.4f action: %d, new mkt %f, reward %f\" % (lastmarket, action, newmarket, reward))\n            r += reward\n            state = np.reshape(state, [1, self.state_size])\n            self.timestep += 1\n        env.render()\n        print(r)\n        env.close()\n        return self.timestep\n\n    def rlplot(self, title='Trading Agent Training Progress'):\n        \"\"\"plot training progress\"\"\"\n        df = pd.DataFrame({'timesteps': self.results})\n        df['avg'] = df['timesteps'].rolling(10).mean()\n\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(x=df.index,\n                                 y=df['timesteps'],\n                                 mode='markers',\n                                 name='timesteps',\n                                 marker=dict(\n                                     color='mediumblue',\n                                     size=4,\n                                 ),\n                                ))\n\n        fig.add_trace(go.Scatter(x=df.index,\n                                 y=df['avg'],\n                                 mode='lines',\n                                 line_width=3,\n                                 name='moving average'))\n\n        fig.update_layout(\n            title=dict(text=title,\n                       x=0.5,\n                       xanchor='center'),\n            xaxis=dict(\n                title=\"Episodes\",\n                linecolor='black',\n                linewidth=1,\n                mirror=True\n            ),\n            yaxis=dict(\n                title=\"Total Reward per Episode\",\n                linecolor='black',\n                linewidth=1,\n                mirror=True\n            ),\n            legend=go.layout.Legend(\n                x=0.01,\n                y=0.99,\n                traceorder=\"normal\",\n                font=dict(\n                    family=\"sans-serif\",\n                    size=12,\n                    color=\"black\"\n                ),\n                #bgcolor=\"LightSteelBlue\",\n                bordercolor=\"Black\",\n                borderwidth=1,\n            ),\n        )\n\n        return fig.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:16:46.767642Z","iopub.execute_input":"2023-11-20T21:16:46.767929Z","iopub.status.idle":"2023-11-20T21:16:46.791739Z","shell.execute_reply.started":"2023-11-20T21:16:46.767901Z","shell.execute_reply":"2023-11-20T21:16:46.790862Z"},"trusted":true},"execution_count":347,"outputs":[]},{"cell_type":"code","source":"class REINFORCE_Agent(Agent):\n    \"\"\"REINFORCE policy gradient method using deep Keras NN\"\"\"\n    def __init__(self, state_size=4, action_size=2, learning_rate=0.005,\n                 discount_rate=DISCOUNT_RATE, n_hidden_layers=2, hidden_layer_size=16,\n                 activation='relu', reg_penalty=0, dropout=0, filename=\"kreinforce\",\n                 verbose=True):\n        self.state_size = state_size\n        self.action_size = action_size\n        self.action_space = list(range(action_size))\n        self.learning_rate = learning_rate\n        self.discount_rate = discount_rate\n\n        self.n_hidden_layers = n_hidden_layers\n        self.hidden_layer_size = hidden_layer_size\n        self.activation = activation\n        self.reg_penalty = reg_penalty\n        self.dropout = dropout\n        self.verbose = verbose\n        self.filename = filename\n\n        self.train_model, self.predict_model = self.policy_model()\n        self.results = []\n        self.save_interval = 10\n        self.reset()\n\n\n    def reset(self):\n        \"\"\"reset agent for start of episode\"\"\"\n        self.timestep = 0\n        # truncate memory\n        self.state_memory = []\n        self.action_memory = []\n        self.reward_memory = []\n        self.total_reward = 0\n\n    def policy_model(self):\n        \"\"\"set up NN model for policy.\n        predict returns probs of actions to sample from.\n        train needs discounted rewards for the episode, so we define custom loss.\n        when training use train_model with custom loss and multi input of training data and rewards.\n        when predicting use predict_model with single input.\n        \"\"\"\n\n        def custom_loss(y_true, y_pred):\n            y_pred_clip = K.clip(y_pred, 1e-8, 1-1e-8)\n            log_likelihood = y_true*K.log(y_pred_clip)\n            return K.sum(-log_likelihood*discounted_rewards)\n\n        inputs = Input(shape=(self.state_size,), name=\"Input\")\n        discounted_rewards = Input(shape=(1,), name=\"Discounted_rewards\")\n        last_layer = inputs\n\n        for i in range(self.n_hidden_layers):\n            if self.verbose:\n                formatstr = \"layer %d size %d, %s, reg_penalty %.8f, dropout %.3f\"\n                print(formatstr % (i + 1,\n                                   self.hidden_layer_size,\n                                   self.activation,\n                                   self.reg_penalty,\n                                   self.dropout,\n                                   ))\n            # add dropout, but not on inputs, only between hidden layers\n            if i and self.dropout:\n                last_layer = Dropout(self.dropout, name=\"Dropout%02d\" % i)(last_layer)\n\n            last_layer = Dense(units=self.hidden_layer_size,\n                               activation=self.activation,\n                               kernel_initializer=glorot_uniform(),\n                               kernel_regularizer=keras.regularizers.l2(self.reg_penalty),\n                               name=\"Dense%02d\" % i)(last_layer)\n\n        outputs = Dense(self.action_size, activation='softmax', name=\"Output\")(last_layer)\n\n        train_model = Model(inputs=[inputs, discounted_rewards], outputs=[outputs])\n        train_model.compile(optimizer=Adam(lr=self.learning_rate), loss=custom_loss)\n\n        predict_model = Model(inputs=[inputs], outputs=[outputs])\n\n        if self.verbose:\n            print(predict_model.summary())\n\n        return train_model, predict_model\n\n\n    def act(self, state):\n        \"\"\"pick an action using predict_model\"\"\"\n        probabilities = self.predict_model.predict(state)\n\n        action = np.random.choice(self.action_space, p=probabilities[0])\n        prob=probabilities[0][action]\n        #print(\"probability={}\\n\".format(probabilities[0][action]))\n        prob_memory.append(prob)\n        return action\n\n    def remember(self):\n        \"\"\"at each step save state, action, reward for future training\"\"\"\n\n        self.state_memory.append(self.state)\n        self.action_memory.append(self.action)\n        self.reward_memory.append(self.reward)\n        \n\n    def train(self):\n        \"\"\"train the model on experience stored by remember\"\"\"\n        state_memory = np.array(self.state_memory)\n        state_memory = state_memory.reshape((len(self.state_memory),self.state_size))\n        action_memory = np.array(self.action_memory)\n        reward_memory = np.array(self.reward_memory)\n\n        # one-hot actions\n        actions = np.zeros([len(action_memory), self.action_size])\n        actions[np.arange(len(action_memory)), action_memory] = 1\n\n        disc_rewards = np.zeros_like(reward_memory)\n        cumulative_rewards = 0\n        for i in reversed(range(len(reward_memory))):\n            cumulative_rewards = cumulative_rewards * self.discount_rate + reward_memory[i]\n            disc_rewards[i] = cumulative_rewards\n\n        # standardize\n        disc_rewards -= np.mean(disc_rewards)\n        disc_rewards /= np.std(disc_rewards) if np.std(disc_rewards) > 0 else 1\n\n        # train states v. actions, (complemented by disc_rewards_std)\n        cost = self.train_model.train_on_batch([state_memory, disc_rewards], actions)\n\n        return cost\n\n    def view(self):\n        \"\"\"Run an episode without training, with rendering\"\"\"\n        state = env.reset()\n        state = np.reshape(state, [1, self.state_size])\n        done = False\n\n        # run an episode\n        self.timestep = 0\n        r = 0\n        retarray = []\n        while not done:\n            action = self.act(state)\n            lastmarket = state[0, self.state_size//2-1]\n            state, reward, done, _ = env.step(action)\n            newmarket = state[0, self.state_size//2-1]\n            print(\"prev mkt: %.4f action: %d, new mkt %.4f, reward %f\" % (lastmarket, action, newmarket, reward))\n            r += reward\n            state = np.reshape(state, [1, self.state_size])\n            self.timestep += 1\n            retarray.append((self.timestep, action, lastmarket, newmarket, reward))\n        print(r)\n        env.close()\n        return retarray\n\n    def save(self):\n        \"save agent: pickle self and use Keras native save model\"\n        fullname = \"%s%s%05d\" % (OUTPUT_DIR, self.filename, len(self.results))\n        self.predict_model.save(\"%s_predict.h5\" % fullname)\n        # can't save / load train model due to custom loss\n        pickle.dump(self, open(\"%s.p\" % fullname, \"wb\"))\n\n    def load(filename, memory=True):\n        \"load saved agent\"\n        self = pickle.load(open(\"%s.p\" % filename, \"rb\"))\n        self.predict_model = load_model(\"%s_predict.h5\" % filename)\n        print(\"loaded %d results, %d rows of memory, epsilon %.4f\" % (len(self.results),\n                                                                      len(self.memory),\n                                                                      self.epsilon))","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:16:46.813280Z","iopub.execute_input":"2023-11-20T21:16:46.813580Z","iopub.status.idle":"2023-11-20T21:16:46.841045Z","shell.execute_reply.started":"2023-11-20T21:16:46.813557Z","shell.execute_reply":"2023-11-20T21:16:46.840179Z"},"trusted":true},"execution_count":348,"outputs":[]},{"cell_type":"code","source":"\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dt=1\n#index_1=[0,6,12,18,24,30,36,42,48,54]\n#index_2=[1,7,13,19,25,31,37,43,49]\n#index_3=[2,8,14,20,26,32,38,44,50]\n#index_4=[3,9,15,21,27,33,39,45,51]\n#index_5=[4,10,16,22,28,34,40,46,52]\n#index_6=[5,11,17,23,29,35,41,47,53]\n\n#index_pick=index_5\nN_EPISODES = 500\n#lag is fixed\nlag = 1\n#ticks_per_episode = len(index_pick)/dt-1-lag\nnstocks = 1\n\n\n#gen = user_sub(df_new,index_1,start_trend=amplifier)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:16:46.865295Z","iopub.execute_input":"2023-11-20T21:16:46.865579Z","iopub.status.idle":"2023-11-20T21:16:46.870009Z","shell.execute_reply.started":"2023-11-20T21:16:46.865555Z","shell.execute_reply":"2023-11-20T21:16:46.869039Z"},"trusted":true},"execution_count":349,"outputs":[]},{"cell_type":"code","source":"#def shm_market_gen():\n#    return market_gen(gen=user_sub(df_new,index_pick,start_trend=amplifier),\n#                      lag=lag)\n\n\n#gen=shm_market_gen()\n#time_series=[]\n#stock_series=[]\n#for i in range(len(index_pick)-lag):\n#    z = next(gen)\n#    time_series.append(i)\n#    stock_series.append(z[1])\n\n#df_gen = pd.DataFrame({'dateindex': time_series, 'stock': stock_series})\n\n#make_figure(df_gen['dateindex'], df_gen['stock'],\n#            title='Genarated market',\n#            xtitle='Timesteps',\n#            ytitle='buffer+diffbuffer'\n#           )","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:16:46.912175Z","iopub.execute_input":"2023-11-20T21:16:46.912465Z","iopub.status.idle":"2023-11-20T21:16:46.917867Z","shell.execute_reply.started":"2023-11-20T21:16:46.912440Z","shell.execute_reply":"2023-11-20T21:16:46.916979Z"},"trusted":true},"execution_count":350,"outputs":[]},{"cell_type":"code","source":"    result_index=[]\n    df_index=Index_Calc(excelfilereader,date)\n    for i in range(len(index_list)):\n        ticks_per_episode = len(index_list[i])/dt-1-lag\n        def shm_market_gen():\n            return market_gen(gen=user_sub(df_index,index_list[i],start_trend=amplifier),lag=1)\n        env = Market(shm_market_gen,\n             lag=lag,\n             nstocks=1,\n             episode_length=ticks_per_episode)\n\n        agent = REINFORCE_Agent(state_size=nstocks*lag*2,\n                        action_size=3,\n                       )\n\n        start_time = time.time()\n        print(\"Start: %s\" % (time.strftime(\"%H:%M:%S\")))\n\n        for e in range(N_EPISODES):\n            agent.run_episode()\n            agent.score_episode(e, N_EPISODES)\n    \n\n    #if e and (e+1) % agent.save_interval == 0:\n    #    agent.save()\n\n        elapsed_time = time.time() - start_time\n        print(\"\\nTrain time: \", elapsed_time)\n        env.reset()\n        z = agent.view()\n\n        df = pd.DataFrame(z)\n        df.columns = [\"timestep\", \"action\", \"lastmarket\", \"newmarket\", \"reward\"]\n        df['lastmarket']+=1\n        df['newmarket']+=1\n        df['short'] = np.nan\n        df.loc[df['action']==0, 'short'] = df['newmarket']\n        df['flat'] = np.nan\n        df.loc[df['action']==1, 'flat'] = df['newmarket']\n        df['long'] = np.nan\n        df.loc[df['action']==2, 'long'] = df['newmarket']\n        df['totalreward'] = df['reward'].cumsum()\n        df.to_csv('df_index_list_{}.csv'.format(i))\n        prob=agent.predict_model.predict(agent.state_memory)\n        action = np.random.choice(agent.action_space, p=prob[0])\n        arr=np.array(df_index['stock'][index_list[i]])\n        mean_diff=np.mean(np.absolute(np.diff(arr)))\n        action_arr=np.array(df['action']-1)\n        pick_index=np.array(df_index['stock'][index_list[i]])\n        wap_future_index=[]\n    #assume in the first time index of t+60 the same as t\n        wap_future_index.append(pick_index[0])\n        for j in range(len(action_arr)):\n            wap_future_index.append(action_arr[j]*mean_diff+pick_index[j+1])\n        wap_future_index.append((action-1)*mean_diff+pick_index[-1])\n        seconds_in_bucket=[j * 10 for j in index_list[i]]\n        comb=list(zip(seconds_in_bucket,pick_index,wap_future_index))\n        result_index.append(comb)\n\n    \n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:16:46.945342Z","iopub.execute_input":"2023-11-20T21:16:46.945665Z","iopub.status.idle":"2023-11-20T21:19:10.269788Z","shell.execute_reply.started":"2023-11-20T21:16:46.945626Z","shell.execute_reply":"2023-11-20T21:19:10.268712Z"},"trusted":true},"execution_count":351,"outputs":[{"name":"stdout","text":"layer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_249\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\nNone\nStart: 21:16:47\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"21:17:12 episode 500/500:, score: 2.4154080000004114, 10-episode avg: 2.3 Memory: 3.8 MB           \nTrain time:  24.909185647964478\nprev mkt: 1.0869 action: 2, new mkt 1.3753, reward 0.288445\nprev mkt: 1.3753 action: 0, new mkt 0.7831, reward 0.592189\nprev mkt: 0.7831 action: 2, new mkt 1.1325, reward 0.349364\nprev mkt: 1.1325 action: 0, new mkt 0.4120, reward 0.720463\nprev mkt: 0.4120 action: 2, new mkt 0.4070, reward -0.005050\nprev mkt: 0.4070 action: 2, new mkt 0.8868, reward 0.479815\nprev mkt: 0.8868 action: 2, new mkt 1.1438, reward 0.256987\nprev mkt: 1.1438 action: 0, new mkt 1.4106, reward -0.266805\n2.4154080000004114\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_251\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\nNone\nStart: 21:17:12\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"21:17:35 episode 500/500:, score: 2.389495999999781, 10-episode avg: 1.9 Memory: 3.8 MB           \nTrain time:  22.931459188461304\nprev mkt: 1.4387 action: 2, new mkt 1.4476, reward 0.008884\nprev mkt: 1.4476 action: 0, new mkt 0.9719, reward 0.475623\nprev mkt: 0.9719 action: 2, new mkt 1.0910, reward 0.119049\nprev mkt: 1.0910 action: 0, new mkt 0.2583, reward 0.832733\nprev mkt: 0.2583 action: 2, new mkt 0.6808, reward 0.422542\nprev mkt: 0.6808 action: 2, new mkt 1.0839, reward 0.403097\nprev mkt: 1.0839 action: 2, new mkt 1.2115, reward 0.127568\n2.389495999999781\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_253\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\nNone\nStart: 21:17:35\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"21:17:58 episode 500/500:, score: 2.3563709999992852, 10-episode avg: 2.3 Memory: 3.8 MB         \nTrain time:  23.036609411239624\nprev mkt: 1.6056 action: 0, new mkt 1.4413, reward 0.164294\nprev mkt: 1.4413 action: 0, new mkt 0.9639, reward 0.477411\nprev mkt: 0.9639 action: 0, new mkt 0.9588, reward 0.005050\nprev mkt: 0.9588 action: 0, new mkt 0.1924, reward 0.766411\nprev mkt: 0.1924 action: 2, new mkt 0.6607, reward 0.468280\nprev mkt: 0.6607 action: 2, new mkt 1.1868, reward 0.526152\nprev mkt: 1.1868 action: 0, new mkt 1.2381, reward -0.051227\n2.3563709999992852\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_255\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\nNone\nStart: 21:17:58\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"21:18:22 episode 500/500:, score: 1.6667510000003176, 10-episode avg: 2.3 Memory: 3.8 MB          \nTrain time:  23.65687870979309\nprev mkt: 1.5710 action: 0, new mkt 1.2090, reward 0.361997\nprev mkt: 1.2090 action: 0, new mkt 1.1077, reward 0.101355\nprev mkt: 1.1077 action: 0, new mkt 0.9792, reward 0.128499\nprev mkt: 0.9792 action: 0, new mkt 0.2306, reward 0.748599\nprev mkt: 0.2306 action: 2, new mkt 0.7184, reward 0.487778\nprev mkt: 0.7184 action: 2, new mkt 1.1566, reward 0.438236\nprev mkt: 1.1566 action: 2, new mkt 1.2809, reward 0.124281\n2.3907449999998107\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_257\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"None\nStart: 21:18:22\n21:18:46 episode 500/500:, score: 1.7486610000004248, 10-episode avg: 1.8 Memory: 3.8 MB           \nTrain time:  23.84268546104431\nprev mkt: 1.2884 action: 0, new mkt 0.7006, reward 0.587806\nprev mkt: 0.7006 action: 2, new mkt 1.1016, reward 0.401022\nprev mkt: 1.1016 action: 2, new mkt 0.9944, reward -0.107207\nprev mkt: 0.9944 action: 0, new mkt 0.5570, reward 0.437407\nprev mkt: 0.5570 action: 2, new mkt 0.6872, reward 0.130228\nprev mkt: 0.6872 action: 2, new mkt 1.0677, reward 0.380528\nprev mkt: 1.0677 action: 2, new mkt 1.3633, reward 0.295537\n2.125321000000099\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_259\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"None\nStart: 21:18:46\n21:19:10 episode 500/500:, score: 1.573694999999816, 10-episode avg: 1.6 Memory: 3.8 MB           \nTrain time:  23.889973640441895\nprev mkt: 1.2153 action: 0, new mkt 0.6253, reward 0.590052\nprev mkt: 0.6253 action: 2, new mkt 1.1916, reward 0.566294\nprev mkt: 1.1916 action: 0, new mkt 1.0193, reward 0.172283\nprev mkt: 1.0193 action: 0, new mkt 0.4650, reward 0.554270\nprev mkt: 0.4650 action: 2, new mkt 0.7779, reward 0.312851\nprev mkt: 0.7779 action: 0, new mkt 1.1098, reward -0.331877\nprev mkt: 1.1098 action: 0, new mkt 1.3999, reward -0.290178\n1.573694999999816\n","output_type":"stream"}]},{"cell_type":"code","source":"from itertools import chain\n\nresult_indx_list = list(chain.from_iterable(result_index))\n#print(result_indx_list)\nsorted_indx_result = sorted(result_indx_list, key=lambda x: x[0])\n#print(sorted_indx_result)\nseconds_in_bucket, wap_index, wap_index_future = zip(*sorted_indx_result)\n#seconds_in_bucket_list=list(seconds_in_bucket)\nwap_index_list=list(wap_index)\nwap_index_future_list=list(wap_index_future)\nprint(list(seconds_in_bucket))\nprint(list(wap_index))\nprint(list(wap_index_future))","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:19:10.271464Z","iopub.execute_input":"2023-11-20T21:19:10.271780Z","iopub.status.idle":"2023-11-20T21:19:10.278877Z","shell.execute_reply.started":"2023-11-20T21:19:10.271753Z","shell.execute_reply":"2023-11-20T21:19:10.277975Z"},"trusted":true},"execution_count":352,"outputs":[{"name":"stdout","text":"[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510, 520, 530, 540]\n[999.9999999999994, 1000.1934979999995, 1000.2803799999991, 1000.5057419999994, 1000.5776239999993, 1000.9211489999994, 1001.0868889999991, 1001.4386759999993, 1001.6055709999994, 1001.571023999999, 1001.2883839999993, 1001.2153459999995, 1001.3753339999994, 1001.4475599999993, 1001.4412769999994, 1001.2090269999993, 1000.7005779999994, 1000.6252939999994, 1000.7831449999993, 1000.9719369999992, 1000.9638659999994, 1001.1076719999992, 1001.1015999999993, 1001.1915879999993, 1001.1325089999993, 1001.0909859999992, 1000.9588159999994, 1000.9791729999993, 1000.9943929999994, 1001.0193049999993, 1000.4120459999995, 1000.2582529999993, 1000.1924049999996, 1000.2305739999993, 1000.5569859999993, 1000.4650349999995, 1000.4069959999995, 1000.6807949999994, 1000.6606849999995, 1000.7183519999994, 1000.6872139999991, 1000.7778859999994, 1000.8868109999993, 1001.0838919999993, 1001.1868369999992, 1001.1565879999993, 1001.0677419999996, 1001.1097629999992, 1001.1437979999995, 1001.2114599999991, 1001.2380639999993, 1001.2808689999993, 1001.3632789999994, 1001.3999409999994, 1001.4106029999994]\n[999.9999999999994, 1000.1934979999995, 1000.2803799999991, 1000.5057419999994, 1000.5776239999993, 1000.9211489999994, 1001.5364453333325, 1001.8930102499993, 1001.1325689999994, 1001.1390206249991, 1000.9070721249993, 1000.8263457499995, 1000.925777666666, 1000.9932257499993, 1000.9682749999995, 1000.7770236249994, 1001.0818898749993, 1001.0142942499994, 1001.2327013333327, 1001.4262712499992, 1000.4908639999994, 1000.6756686249993, 1001.4829118749992, 1000.8025877499994, 1000.682952666666, 1000.6366517499993, 1000.4858139999994, 1000.5471696249994, 1000.6130811249994, 1000.6303047499994, 1000.8616023333328, 1000.7125872499993, 1000.6654069999995, 1000.6625773749992, 1000.9382978749992, 1000.8540352499995, 1000.8565523333328, 1001.1351292499994, 1001.1336869999994, 1001.1503553749993, 1001.0685258749991, 1000.3888857499994, 1001.3363673333326, 1001.5382262499993, 1000.7138349999992, 1001.5885913749992, 1001.4490538749995, 1000.7207627499993, 1000.6942416666661, 1001.6657942499991, 1000.7650619999994, 1000.8488656249993, 1000.9819671249994, 1001.0109407499995, 1001.8601593333327]\n","output_type":"stream"}]},{"cell_type":"code","source":"result=[]\n\nfor i in range(len(index_list)):\n    ticks_per_episode = len(index_list[i])/dt-1-lag\n    def shm_market_gen():\n        return market_gen(gen=user_sub(df_new,index_list[i],start_trend=amplifier),\n                      lag=1)\n\n    env = Market(shm_market_gen,\n             lag=lag,\n             nstocks=1,\n             episode_length=ticks_per_episode)\n\n    agent = REINFORCE_Agent(state_size=nstocks*lag*2,\n                        action_size=3,\n                       )\n\n    start_time = time.time()\n    print(\"Start: %s\" % (time.strftime(\"%H:%M:%S\")))\n\n    for e in range(N_EPISODES):\n        agent.run_episode()\n        agent.score_episode(e, N_EPISODES)\n    \n\n    #if e and (e+1) % agent.save_interval == 0:\n    #    agent.save()\n\n    elapsed_time = time.time() - start_time\n    print(\"\\nTrain time: \", elapsed_time)\n    env.reset()\n    z = agent.view()\n\n    df = pd.DataFrame(z)\n    df.columns = [\"timestep\", \"action\", \"lastmarket\", \"newmarket\", \"reward\"]\n    df['lastmarket']+=1\n    df['newmarket']+=1\n    df['short'] = np.nan\n    df.loc[df['action']==0, 'short'] = df['newmarket']\n    df['flat'] = np.nan\n    df.loc[df['action']==1, 'flat'] = df['newmarket']\n    df['long'] = np.nan\n    df.loc[df['action']==2, 'long'] = df['newmarket']\n    df['totalreward'] = df['reward'].cumsum()\n    df.to_csv('df_list_{}.csv'.format(i))\n    prob=agent.predict_model.predict(agent.state_memory)\n    action = np.random.choice(agent.action_space, p=prob[0])\n    pick_index=np.array(df_new['stock'][index_list[i]])\n    mean_diff=np.mean(np.absolute(np.diff(arr)))\n    action_arr=np.array(df['action']-1)\n    #pick_index=np.array(df_new['stock'][index_list[i]])\n    wap_future_index=[]\n    #assume in the first time index of t+60 the same as t\n    wap_future_index.append(pick_index[0])\n    for j in range(len(action_arr)):\n        wap_future_index.append(action_arr[j]*mean_diff+pick_index[j+1])\n    wap_future_index.append((action-1)*mean_diff+pick_index[-1])\n    seconds_in_bucket=[j * 10 for j in index_list[i]]\n    comb=list(zip(seconds_in_bucket,pick_index,wap_future_index))\n    result.append(comb)\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:19:10.280277Z","iopub.execute_input":"2023-11-20T21:19:10.280601Z","iopub.status.idle":"2023-11-20T21:21:39.360577Z","shell.execute_reply.started":"2023-11-20T21:19:10.280576Z","shell.execute_reply":"2023-11-20T21:21:39.359540Z"},"trusted":true},"execution_count":353,"outputs":[{"name":"stdout","text":"layer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_261\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\nNone\nStart: 21:19:10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"21:19:36 episode 500/500:, score: 3.6479999999993424, 10-episode avg: 3.6 Memory: 3.8 MB         \nTrain time:  25.870177030563354\nprev mkt: -0.0740 action: 2, new mkt 0.8860, reward 0.960000\nprev mkt: 0.8860 action: 0, new mkt 0.2260, reward 0.660000\nprev mkt: 0.2260 action: 2, new mkt 0.4600, reward 0.234000\nprev mkt: 0.4600 action: 0, new mkt -0.0500, reward 0.510000\nprev mkt: -0.0500 action: 2, new mkt 0.2480, reward 0.298000\nprev mkt: 0.2480 action: 2, new mkt 0.6650, reward 0.417000\nprev mkt: 0.6650 action: 0, new mkt 0.1880, reward 0.477000\nprev mkt: 0.1880 action: 2, new mkt 0.2800, reward 0.092000\n3.6479999999993424\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_263\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"None\nStart: 21:19:36\n21:20:00 episode 500/500:, score: 2.8169999999995525, 10-episode avg: 2.5 Memory: 3.8 MB          \nTrain time:  24.1154043674469\nprev mkt: 0.5270 action: 2, new mkt 1.2150, reward 0.688000\nprev mkt: 1.2150 action: 0, new mkt 0.2390, reward 0.976000\nprev mkt: 0.2390 action: 2, new mkt 0.1950, reward -0.044000\nprev mkt: 0.1950 action: 2, new mkt 0.0360, reward -0.159000\nprev mkt: 0.0360 action: 2, new mkt 0.2600, reward 0.224000\nprev mkt: 0.2600 action: 2, new mkt 0.6750, reward 0.415000\nprev mkt: 0.6750 action: 0, new mkt 0.2760, reward 0.399000\n2.498999999999569\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_265\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\nNone\nStart: 21:20:00\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"21:20:25 episode 500/500:, score: 2.8000000000004093, 10-episode avg: 2.8 Memory: 3.8 MB          \nTrain time:  24.80647897720337\nprev mkt: 0.7770 action: 0, new mkt 1.1920, reward -0.415000\nprev mkt: 1.1920 action: 0, new mkt 0.6330, reward 0.559000\nprev mkt: 0.6330 action: 0, new mkt -0.1020, reward 0.735000\nprev mkt: -0.1020 action: 2, new mkt 0.4370, reward 0.539000\nprev mkt: 0.4370 action: 0, new mkt 0.1900, reward 0.247000\nprev mkt: 0.1900 action: 2, new mkt 0.8390, reward 0.649000\nprev mkt: 0.8390 action: 0, new mkt 0.3530, reward 0.486000\n2.8000000000004093\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_267\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"None\nStart: 21:20:25\n21:20:49 episode 500/500:, score: 2.9849999999996726, 10-episode avg: 3.0 Memory: 3.8 MB          \nTrain time:  24.336355209350586\nprev mkt: 0.8650 action: 0, new mkt 0.9580, reward -0.093000\nprev mkt: 0.9580 action: 0, new mkt 0.6570, reward 0.301000\nprev mkt: 0.6570 action: 0, new mkt -0.1410, reward 0.798000\nprev mkt: -0.1410 action: 2, new mkt 0.4400, reward 0.581000\nprev mkt: 0.4400 action: 0, new mkt 0.2060, reward 0.234000\nprev mkt: 0.2060 action: 2, new mkt 0.8400, reward 0.634000\nprev mkt: 0.8400 action: 0, new mkt 0.3100, reward 0.530000\n2.9849999999996726\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_269\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"None\nStart: 21:20:50\n21:21:14 episode 500/500:, score: 2.3599999999997863, 10-episode avg: 2.5 Memory: 3.8 MB        \nTrain time:  24.38215160369873\nprev mkt: 1.1100 action: 0, new mkt 0.0430, reward 1.067000\nprev mkt: 0.0430 action: 2, new mkt 0.7090, reward 0.666000\nprev mkt: 0.7090 action: 0, new mkt 0.4980, reward 0.211000\nprev mkt: 0.4980 action: 0, new mkt 0.4640, reward 0.034000\nprev mkt: 0.4640 action: 0, new mkt 0.2840, reward 0.180000\nprev mkt: 0.2840 action: 2, new mkt 0.5490, reward 0.265000\nprev mkt: 0.5490 action: 0, new mkt 0.3470, reward 0.202000\n2.624999999999659\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_271\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"None\nStart: 21:21:14\n21:21:39 episode 500/500:, score: 2.5900000000001455, 10-episode avg: 2.6 Memory: 3.8 MB          \nTrain time:  24.72252106666565\nprev mkt: 1.0010 action: 0, new mkt -0.1710, reward 1.172000\nprev mkt: -0.1710 action: 2, new mkt 0.5560, reward 0.727000\nprev mkt: 0.5560 action: 0, new mkt 0.4600, reward 0.096000\nprev mkt: 0.4600 action: 0, new mkt 0.2010, reward 0.259000\nprev mkt: 0.2010 action: 2, new mkt 0.4600, reward 0.259000\nprev mkt: 0.4600 action: 0, new mkt 0.4990, reward -0.039000\nprev mkt: 0.4990 action: 0, new mkt 0.3830, reward 0.116000\n2.5900000000001455\n","output_type":"stream"}]},{"cell_type":"code","source":"\nresult_list = list(chain.from_iterable(result))\n#print(result_list)\nsorted_result = sorted(result_list, key=lambda x: x[0])\n#print(sorted_result)\nseconds_in_bucket, wap, wap_future = zip(*sorted_result)\nseconds_in_bucket_list=list(seconds_in_bucket)\nwap_list=list(wap)\nwap_future_list=list(wap_future)\n#print(list(seconds_in_bucket))\n#print(list(wap))\n#print(list(wap_future))\ntarget_out=[]\nfor i in range(len(seconds_in_bucket_list)):\n    target_out.append((wap_future_list[i]/wap_list[i]-wap_index_future_list[i]/wap_index_list[i])*10000)\n\nprint(target_out)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:21:39.364033Z","iopub.execute_input":"2023-11-20T21:21:39.364667Z","iopub.status.idle":"2023-11-20T21:21:39.371597Z","shell.execute_reply.started":"2023-11-20T21:21:39.364637Z","shell.execute_reply":"2023-11-20T21:21:39.370728Z"},"trusted":true},"execution_count":354,"outputs":[{"name":"stdout","text":"[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.6003920784780625, -0.6488619439548593, 0.835455476091429, 0.42661696299961527, -0.07747707459260234, -0.0008319615485419263, 0.6028299153892913, 0.6514933631118769, 0.837841404791595, 0.42853757543093174, 0.07938600398826878, 0.0030961794061923342, -0.6029218523551094, -0.6498579335256771, 0.8379235985644939, 0.42780541775089276, -7.696169282870313, -0.0024681240096136037, 0.6022639051850298, 8.427635276162526, 8.615888446147357, 8.206358895200827, -0.07873546487235927, -0.0021724830645553084, -0.6035147075444947, -0.6523070061548175, -8.617413407023822, -8.207329543828967, -7.699194454490188, 0.0010264130878567812, -0.6046963828354457, -0.6512601572206123, -0.837633470121002, -0.42773134825146997, 0.07839793198405332, -0.0012350480438350075, -8.37899751810034, -8.425801858750193, 0.8376713681157444, -8.201780663401603, -7.696919725990181, -0.0023720522135395328, 8.379698508684807, -0.648915926644289, 0.8355413600646955, 0.4257104582416904, -0.08072565493288941, -0.003948860330948989, -0.6003172066937346]\n","output_type":"stream"}]},{"cell_type":"code","source":"excelfilereader=pd.read_csv(r'/kaggle/input/optiver-trading-at-the-close/example_test_files/revealed_targets.csv')\ndata_sub=excelfilereader[excelfilereader['stock_id']==stock]\ndata_sub2=data_sub[data_sub['revealed_date_id']==date]\ndata=pd.DataFrame(data_sub2,columns=['revealed_target'])\ndata = data.values.tolist()\ndata=np.squeeze(data)\n#print(data)\n\nplt.plot(data,label=\"truth\")\nplt.plot(target_out,label=\"Calculated\")\nplt.ylabel('Target')\nplt.title('Target of stock {} at date {}'.format(stock,date))\nplt.legend()\nplt.show()\n\nfrom sklearn.metrics import mean_absolute_error as mae\nerror = mae(data, target_out) \n\nprint(\"Mean absolute error : \" + str(error)) ","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:21:39.372481Z","iopub.execute_input":"2023-11-20T21:21:39.372761Z","iopub.status.idle":"2023-11-20T21:21:40.136368Z","shell.execute_reply.started":"2023-11-20T21:21:39.372736Z","shell.execute_reply":"2023-11-20T21:21:40.135426Z"},"trusted":true},"execution_count":355,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"Mean absolute error : 3.619015599172053\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#agent.rlplot(\"Training Progress: stock {} date {}\".format(int(stock),int(date)))","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:21:40.137650Z","iopub.execute_input":"2023-11-20T21:21:40.137931Z","iopub.status.idle":"2023-11-20T21:21:40.142032Z","shell.execute_reply.started":"2023-11-20T21:21:40.137906Z","shell.execute_reply":"2023-11-20T21:21:40.141199Z"},"trusted":true},"execution_count":356,"outputs":[]},{"cell_type":"code","source":"#env.reset()\n#z = agent.view()\n\n#df = pd.DataFrame(z)\n#df.columns = [\"timestep\", \"action\", \"lastmarket\", \"newmarket\", \"reward\"]\n#df['lastmarket']+=1\n#df['newmarket']+=1\n#df['short'] = np.nan\n#df.loc[df['action']==0, 'short'] = df['newmarket']\n#df['flat'] = np.nan\n#df.loc[df['action']==1, 'flat'] = df['newmarket']\n#df['long'] = np.nan\n#df.loc[df['action']==2, 'long'] = df['newmarket']\n#df['totalreward'] = df['reward'].cumsum()\n#df.to_csv('df.csv')\n#df","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:21:40.143278Z","iopub.execute_input":"2023-11-20T21:21:40.143555Z","iopub.status.idle":"2023-11-20T21:21:40.156037Z","shell.execute_reply.started":"2023-11-20T21:21:40.143530Z","shell.execute_reply":"2023-11-20T21:21:40.155163Z"},"trusted":true},"execution_count":357,"outputs":[]},{"cell_type":"code","source":"#def tradesim_chart(df, title=\"Trading Simulation\"):\n\n#    fig = go.Figure()\n#    markersize=4\n\n    # x axis\n#    x = df['timestep']\n\n#    red = 'rgba(192, 32, 32, 0.75)'\n#    blue = 'rgba(32, 32, 192, 0.75)'\n#    green = 'rgba(0, 204, 0, 0.75)'\n#    black = 'rgba(32, 32, 32, 0.75)'\n\n#    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n#    fig.add_trace(go.Scatter(y=df['short'],\n#                             x=x,\n#                             name='Short (left axis)',\n#                             mode='markers',\n#                             marker=dict(size=markersize,\n#                                         color=red),\n#                            ),\n #                 secondary_y=False,\n #                )\n\n  #  fig.add_trace(go.Scatter(y=df['flat'],\n  #                           x=x,\n  #                           name='Flat (left axis)',\n  #                           mode='markers',\n  #                           marker=dict(size=markersize,\n  #                                       color=blue),\n  #                          ),\n  #                secondary_y=False,\n  #               )\n\n  #  fig.add_trace(go.Scatter(y=df['long'],\n#                          x=x,\n#                             name='Long (left axis)',\n#                             mode='markers',\n#                             marker=dict(size=markersize,\n#                                         color=green),\n#                            ),\n#                  secondary_y=False,\n#                 )\n\n #   fig.add_trace(go.Scatter(y=df['totalreward'],\n #                            x=x,\n #                            name='Total reward (right)',\n  #                           mode='markers',\n  #                           marker=dict(size=markersize,\n  #                                       color=black),\n  #                          ),\n  #                secondary_y=True,\n  #               )\n\n    # plot attributes\n  #  fig.update_layout(\n  #      title= dict(text=title,\n  #                  x=0.5,\n  #                  xanchor='center'),\n  #      xaxis=dict(\n  #          title=\"Timesteps\",\n  #          linecolor='black',\n  #          linewidth=1,\n  #          mirror=True\n  #      ),\n  #      yaxis=dict(\n  #          title=\"Price\",\n  #          linecolor='black',\n  #          linewidth=1,\n  #          mirror=True\n  #      ),\n  #      showlegend=True,\n  #      legend=dict(x=0.738, y=0.05)\n  #  )\n\n  #  fig.update_yaxes(title_text=\"Total reward\", secondary_y=True)\n\n  #  fig.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:21:40.157443Z","iopub.execute_input":"2023-11-20T21:21:40.157740Z","iopub.status.idle":"2023-11-20T21:21:40.170203Z","shell.execute_reply.started":"2023-11-20T21:21:40.157716Z","shell.execute_reply":"2023-11-20T21:21:40.169552Z"},"trusted":true},"execution_count":358,"outputs":[]},{"cell_type":"code","source":"#tradesim_chart(df, title=\"Trading stock {} date {}\".format(int(stock),int(date)))","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:21:40.171086Z","iopub.execute_input":"2023-11-20T21:21:40.171331Z","iopub.status.idle":"2023-11-20T21:21:40.186124Z","shell.execute_reply.started":"2023-11-20T21:21:40.171309Z","shell.execute_reply":"2023-11-20T21:21:40.185277Z"},"trusted":true},"execution_count":359,"outputs":[]},{"cell_type":"code","source":"#prob=agent.predict_model.predict(agent.state_memory)\n#print(prob)\n#action = np.random.choice(agent.action_space, p=prob[0])\n#print(action)\n#action\n#arr=np.array(df_new['stock'][index_pick])\n#mean_diff=np.mean(np.absolute(np.diff(arr)))\n#action_arr=np.array(df['action']-1)\n#print(action_arr)\n#pick=np.array(df_new['stock'][index_pick])\n#wap_future=[]\n#assume the first stock i\n#wap_future.append(pick[0])\n#for i in range(len(action_arr)):\n#    wap_future.append(action_arr[i]*mean_diff+pick[i+1])\n#index=[1,2,3,4,5,6,7,8,9]\n#wap_future.append((action-1)*mean_diff+pick[-1])\n#plt.plot(pick,\"*\",label=\"truth\")\n#plt.plot(index,wap_future,\"*\",label=\"prediction\")\n#plt.legend()\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:21:40.189509Z","iopub.execute_input":"2023-11-20T21:21:40.189818Z","iopub.status.idle":"2023-11-20T21:21:40.197480Z","shell.execute_reply.started":"2023-11-20T21:21:40.189796Z","shell.execute_reply":"2023-11-20T21:21:40.196035Z"},"trusted":true},"execution_count":360,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def shm_market_gen():\n#    return market_gen(gen=user_sub(df_index,index_pick,start_trend=amplifier),\n#                      lag=lag)\n\n#env = Market(shm_market_gen,\n#             lag=lag,\n#             nstocks=1,\n#             episode_length=ticks_per_episode)\n\n#agent = REINFORCE_Agent(state_size=nstocks*lag*2,\n#                        action_size=3,\n#                       )\n#agent.reset()\n#start_time = time.time()\n#print(\"Start: %s\" % (time.strftime(\"%H:%M:%S\")))\n\n#for e in range(N_EPISODES):\n#    agent.run_episode()\n#    agent.score_episode(e, N_EPISODES)\n    \n\n    #if e and (e+1) % agent.save_interval == 0:\n    #    agent.save()\n\n#elapsed_time = time.time() - start_time\n#print(\"\\nTrain time: \", elapsed_time)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:21:40.199016Z","iopub.execute_input":"2023-11-20T21:21:40.199330Z","iopub.status.idle":"2023-11-20T21:21:40.208316Z","shell.execute_reply.started":"2023-11-20T21:21:40.199302Z","shell.execute_reply":"2023-11-20T21:21:40.207471Z"},"trusted":true},"execution_count":361,"outputs":[]},{"cell_type":"code","source":"#agent.rlplot(\"Training Progress: Index date {}\".format(int(date)))","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:21:40.210146Z","iopub.execute_input":"2023-11-20T21:21:40.210757Z","iopub.status.idle":"2023-11-20T21:21:40.219259Z","shell.execute_reply.started":"2023-11-20T21:21:40.210732Z","shell.execute_reply":"2023-11-20T21:21:40.218437Z"},"trusted":true},"execution_count":362,"outputs":[]},{"cell_type":"code","source":"#prob=agent.predict_model.predict(agent.state_memory)\n#print(prob)\n#action = np.random.choice(agent.action_space, p=prob[0])\n#print(action)\n#action\n#arr=np.array(df_index['stock'][index_pick])\n#mean_diff=np.mean(np.absolute(np.diff(arr)))\n#print(np.mean(np.absolute(np.diff(arr))))\n#action_arr=np.array(df['action']-1)\n#print(action_arr)\n#pick_index=np.array(df_index['stock'][index_pick])\n#wap_future_index=[]\n#assume in the first time index of t+60 the same as t\n#wap_future_index.append(pick_index[0])\n#for i in range(len(action_arr)):\n#    wap_future_index.append(action_arr[i]*mean_diff+pick_index[i+1])\n#index=[1,2,3,4,5,6,7,8,9]\n#wap_future_index.append((action-1)*mean_diff+pick_index[-1])\n#plt.plot(pick_index,\"*\",label=\"truth\")\n#plt.plot(index,wap_future_index,\"*\",label=\"prediction\")\n#plt.legend()\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:21:40.220240Z","iopub.execute_input":"2023-11-20T21:21:40.220558Z","iopub.status.idle":"2023-11-20T21:21:40.232471Z","shell.execute_reply.started":"2023-11-20T21:21:40.220522Z","shell.execute_reply":"2023-11-20T21:21:40.231517Z"},"trusted":true},"execution_count":363,"outputs":[]},{"cell_type":"code","source":"#def target():\n#    target_out=[]\n#    for i in range(len(index_pick)):\n#        target_out.append((wap_future[i]/pick[i]-wap_future_index[i]/pick_index[i])*10000)\n#    return target_out\n\n#seconds_in_bucket=[i * 10 for i in index_pick]\n#comb=list(zip(seconds_in_bucket,target()))\n#print(\"day=\",date,\"Stock=\",stock,\"seconds_in_bucket\", seconds_in_bucket, target())\n#print(comb)        \n#sorted_zipped = sorted(comb, key=lambda x: x[0])    \n#sorted_list1, sorted_list2 = zip(*sorted_zipped)\n#print(list(sorted_list1))\n#print(list(sorted_list2))","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:21:40.233453Z","iopub.execute_input":"2023-11-20T21:21:40.233765Z","iopub.status.idle":"2023-11-20T21:21:40.251544Z","shell.execute_reply.started":"2023-11-20T21:21:40.233741Z","shell.execute_reply":"2023-11-20T21:21:40.250800Z"},"trusted":true},"execution_count":364,"outputs":[]},{"cell_type":"code","source":"#env = Market(shm_market_gen,\n#             lag=lag,\n#             nstocks=1,\n#             episode_length=ticks_per_episode)\n#env.reset()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:21:40.252564Z","iopub.execute_input":"2023-11-20T21:21:40.252845Z","iopub.status.idle":"2023-11-20T21:21:40.264424Z","shell.execute_reply.started":"2023-11-20T21:21:40.252820Z","shell.execute_reply":"2023-11-20T21:21:40.263429Z"},"trusted":true},"execution_count":365,"outputs":[]},{"cell_type":"code","source":"import optiver2023\nenv = optiver2023.make_env()\niter_test = env.iter_test()\ncounter = 0\nfor (test, revealed_targets, sample_prediction) in iter_test:\n    stock=test['stock_id']\n    date=test['date_id']\n    amplifier=1000\n    df_new=Data_input(test,stock,date,amplifier)\n    result_index=[]\n    df_index=Index_Calc(test,date)\n    for i in range(len(index_list)):\n        ticks_per_episode = len(index_list[i])/dt-1-lag\n        def shm_market_gen():\n            return market_gen(gen=user_sub(df_index,index_list[i],start_trend=amplifier),lag=1)\n        env = Market(shm_market_gen,\n             lag=lag,\n             nstocks=1,\n             episode_length=ticks_per_episode)\n\n        agent = REINFORCE_Agent(state_size=nstocks*lag*2,\n                        action_size=3,\n                       )\n\n        start_time = time.time()\n        print(\"Start: %s\" % (time.strftime(\"%H:%M:%S\")))\n\n        for e in range(N_EPISODES):\n            agent.run_episode()\n            agent.score_episode(e, N_EPISODES)\n    \n\n    #if e and (e+1) % agent.save_interval == 0:\n    #    agent.save()\n\n        elapsed_time = time.time() - start_time\n        print(\"\\nTrain time: \", elapsed_time)\n        env.reset()\n        z = agent.view()\n\n        df = pd.DataFrame(z)\n        df.columns = [\"timestep\", \"action\", \"lastmarket\", \"newmarket\", \"reward\"]\n        df['lastmarket']+=1\n        df['newmarket']+=1\n        df['short'] = np.nan\n        df.loc[df['action']==0, 'short'] = df['newmarket']\n        df['flat'] = np.nan\n        df.loc[df['action']==1, 'flat'] = df['newmarket']\n        df['long'] = np.nan\n        df.loc[df['action']==2, 'long'] = df['newmarket']\n        df['totalreward'] = df['reward'].cumsum()\n        df.to_csv('df_index_list_{}.csv'.format(i))\n        prob=agent.predict_model.predict(agent.state_memory)\n        action = np.random.choice(agent.action_space, p=prob[0])\n        arr=np.array(df_index['stock'][index_list[i]])\n        mean_diff=np.mean(np.absolute(np.diff(arr)))\n        action_arr=np.array(df['action']-1)\n        pick_index=np.array(df_index['stock'][index_list[i]])\n        wap_future_index=[]\n    #assume in the first time index of t+60 the same as t\n        wap_future_index.append(pick_index[0])\n        for j in range(len(action_arr)):\n            wap_future_index.append(action_arr[j]*mean_diff+pick_index[j+1])\n        wap_future_index.append((action-1)*mean_diff+pick_index[-1])\n        seconds_in_bucket=[j * 10 for j in index_list[i]]\n        comb=list(zip(seconds_in_bucket,pick_index,wap_future_index))\n        result_index.append(comb)\n    result_indx_list = list(chain.from_iterable(result_index))\n\n    sorted_indx_result = sorted(result_indx_list, key=lambda x: x[0])\n\n    seconds_in_bucket, wap_index, wap_index_future = zip(*sorted_indx_result)\n\n    wap_index_list=list(wap_index)\n    wap_index_future_list=list(wap_index_future)\n    \n    result=[]\n\n    for i in range(len(index_list)):\n        ticks_per_episode = len(index_list[i])/dt-1-lag\n        def shm_market_gen():\n            return market_gen(gen=user_sub(df_new,index_list[i],start_trend=amplifier),\n                      lag=1)\n\n        env = Market(shm_market_gen,\n             lag=lag,\n             nstocks=1,\n             episode_length=ticks_per_episode)\n\n        agent = REINFORCE_Agent(state_size=nstocks*lag*2,\n                        action_size=3,\n                       )\n\n        start_time = time.time()\n        print(\"Start: %s\" % (time.strftime(\"%H:%M:%S\")))\n\n        for e in range(N_EPISODES):\n            agent.run_episode()\n            agent.score_episode(e, N_EPISODES)\n    \n\n    #if e and (e+1) % agent.save_interval == 0:\n    #    agent.save()\n\n        elapsed_time = time.time() - start_time\n        print(\"\\nTrain time: \", elapsed_time)\n        env.reset()\n        z = agent.view()\n\n        df = pd.DataFrame(z)\n        df.columns = [\"timestep\", \"action\", \"lastmarket\", \"newmarket\", \"reward\"]\n        df['lastmarket']+=1\n        df['newmarket']+=1\n        df['short'] = np.nan\n        df.loc[df['action']==0, 'short'] = df['newmarket']\n        df['flat'] = np.nan\n        df.loc[df['action']==1, 'flat'] = df['newmarket']\n        df['long'] = np.nan\n        df.loc[df['action']==2, 'long'] = df['newmarket']\n        df['totalreward'] = df['reward'].cumsum()\n        df.to_csv('df_list_{}.csv'.format(i))\n        prob=agent.predict_model.predict(agent.state_memory)\n        action = np.random.choice(agent.action_space, p=prob[0])\n        pick_index=np.array(df_new['stock'][index_list[i]])\n        mean_diff=np.mean(np.absolute(np.diff(arr)))\n        action_arr=np.array(df['action']-1)\n    #pick_index=np.array(df_new['stock'][index_list[i]])\n        wap_future_index=[]\n    #assume in the first time index of t+60 the same as t\n        wap_future_index.append(pick_index[0])\n        for j in range(len(action_arr)):\n            wap_future_index.append(action_arr[j]*mean_diff+pick_index[j+1])\n        wap_future_index.append((action-1)*mean_diff+pick_index[-1])\n        seconds_in_bucket=[j * 10 for j in index_list[i]]\n        comb=list(zip(seconds_in_bucket,pick_index,wap_future_index))\n        result.append(comb)\n    result_list = list(chain.from_iterable(result))\n    sorted_result = sorted(result_list, key=lambda x: x[0])\n    seconds_in_bucket, wap, wap_future = zip(*sorted_result)\n    seconds_in_bucket_list=list(seconds_in_bucket)\n    wap_list=list(wap)\n    wap_future_list=list(wap_future)\n\n    target_out=[]\n    for i in range(len(seconds_in_bucket_list)):\n        target_out.append((wap_future_list[i]/wap_list[i]-wap_index_future_list[i]/wap_index_list[i])*10000)\n\n\n    \n    sample_prediction['target'] = target_out\n    env.predict(sample_prediction)\n    counter += 1","metadata":{"execution":{"iopub.status.busy":"2023-11-20T21:21:40.265684Z","iopub.execute_input":"2023-11-20T21:21:40.266065Z","iopub.status.idle":"2023-11-20T21:21:41.418085Z","shell.execute_reply.started":"2023-11-20T21:21:40.266030Z","shell.execute_reply":"2023-11-20T21:21:41.417075Z"},"trusted":true},"execution_count":366,"outputs":[{"name":"stdout","text":"This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n","output_type":"stream"}]}]}