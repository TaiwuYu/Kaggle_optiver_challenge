{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57891,"databundleVersionId":7056235,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-21T00:51:21.563589Z","iopub.execute_input":"2023-11-21T00:51:21.564363Z","iopub.status.idle":"2023-11-21T00:51:21.577929Z","shell.execute_reply.started":"2023-11-21T00:51:21.564314Z","shell.execute_reply":"2023-11-21T00:51:21.576407Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"/kaggle/input/optiver-trading-at-the-close/public_timeseries_testing_util.py\n/kaggle/input/optiver-trading-at-the-close/train.csv\n/kaggle/input/optiver-trading-at-the-close/example_test_files/sample_submission.csv\n/kaggle/input/optiver-trading-at-the-close/example_test_files/revealed_targets.csv\n/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv\n/kaggle/input/optiver-trading-at-the-close/optiver2023/competition.cpython-310-x86_64-linux-gnu.so\n/kaggle/input/optiver-trading-at-the-close/optiver2023/__init__.py\n","output_type":"stream"}]},{"cell_type":"code","source":"#Instal new version of Tensorflow\n#!pip3 install --upgrade tensorflow==2.12.0","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:51:21.626741Z","iopub.execute_input":"2023-11-21T00:51:21.627174Z","iopub.status.idle":"2023-11-21T00:51:21.632935Z","shell.execute_reply.started":"2023-11-21T00:51:21.627139Z","shell.execute_reply":"2023-11-21T00:51:21.631347Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"import random\nfrom datetime import datetime\nimport time\nimport resource\nimport pickle\nimport os\nimport pdb\nfrom tqdm import tqdm\nfrom itertools import chain\n\nimport numpy as np\nimport pandas as pd\nimport keras\nfrom scipy.interpolate import pchip_interpolate\n\nimport tensorflow as tf\n#import tensorflow.keras\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Input, Dense, Dropout\n#In old version of Tensorflow 2.8.0\n#from tensorflow.keras.optimizers import Adam\n#In new version of Tensorflow 2.12.0, please use legacy to import Adam\nfrom tensorflow.keras.optimizers.legacy import Adam\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.regularizers import l2\nimport tensorflow.keras.backend as K\n#from keras import backend as K\n\nimport plotly\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nfrom IPython.display import clear_output, display, HTML\n\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# originally built on old TensorFlow and Keras which didn't support eager execution\ntf.compat.v1.disable_eager_execution()\n#tf.compat.v1.disable_v2_behavior()\n#tf.compat.v1.enable_eager_execution()\n\n# set seeds for reproducibility\n# np.random.uniform(0,10000) 4465\nrandom.seed(4465)\nnp.random.seed(4465)\ntf.random.set_seed(4465)\n\nprint(\"TensorFlow %s\" % tf.__version__)\nprint(\"Keras %s\" % keras.__version__)\nprint(\"plotly %s\" % plotly.__version__)\nprint(\"pandas %s\" % pd.__version__)\nprint(\"numpy %s\" % np.__version__)\n\n# If model save directory isn't made yet, make it\nif not os.path.exists('model_output'):\n    os.makedirs('model_output')\nif not os.path.exists('model_output/trading'):\n    os.makedirs('model_output/trading')","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:51:21.683489Z","iopub.execute_input":"2023-11-21T00:51:21.683938Z","iopub.status.idle":"2023-11-21T00:51:21.700810Z","shell.execute_reply.started":"2023-11-21T00:51:21.683903Z","shell.execute_reply":"2023-11-21T00:51:21.698529Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"TensorFlow 2.12.0\nKeras 2.12.0\nplotly 5.15.0\npandas 2.0.3\nnumpy 1.23.5\n","output_type":"stream"}]},{"cell_type":"code","source":"def sizeof_fmt(num, suffix='B'):\n    \"\"\"given memory as int format as memory units eg KB\"\"\"\n    for unit in ['', 'K', 'M', 'G', 'T', 'P', 'E', 'Z']:\n        if abs(num) < 1024.0:\n            return \"%3.1f %s%s\" % (num, unit, suffix)\n        num /= 1024.0\n    return \"%.1f %s%s\" % (num, 'Y', suffix)\n\ndef memusage():\n    \"\"\"print memory usage\"\"\"\n    return sizeof_fmt(int(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss))\n\nmemusage()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:51:21.734054Z","iopub.execute_input":"2023-11-21T00:51:21.734470Z","iopub.status.idle":"2023-11-21T00:51:21.745911Z","shell.execute_reply.started":"2023-11-21T00:51:21.734437Z","shell.execute_reply":"2023-11-21T00:51:21.744654Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"'598.6 KB'"},"metadata":{}}]},{"cell_type":"code","source":"def make_figure(*series, title=\"\", xtitle=\"\", ytitle=\"\"):\n    fig = go.Figure()\n    series=list(series)\n    x = series.pop(0)\n    for s in series:\n        fig.add_trace(go.Scatter(y=s, x=x))\n    fig.update_layout(\n        title= dict(text=title,\n                    x=0.5,\n                    xanchor='center'),\n        xaxis=dict(\n            title=xtitle,\n            linecolor='black',\n            linewidth=1,\n            mirror=True\n        ),\n        yaxis=dict(\n            title=ytitle,\n            linecolor='black',\n            linewidth=1,\n            mirror=True\n        ),\n        showlegend=False\n    )\n\n    return fig.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:51:21.794312Z","iopub.execute_input":"2023-11-21T00:51:21.794763Z","iopub.status.idle":"2023-11-21T00:51:21.803860Z","shell.execute_reply.started":"2023-11-21T00:51:21.794727Z","shell.execute_reply":"2023-11-21T00:51:21.802680Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"stock_series = []\n\n\namplifier=1000\ndate=478\nstock=46\n#be cautious when setting dt. dt is inverse proportional to learning time dt=1 means no optimization\ndt=1\nN_EPISODES = 500\n#lag is fixed\nlag = 1\n\n#filename=\"IndexWap_day231.csv\"\n#excelfilereader=pd.read_csv(r'/content/kaggle_optiver_data/IndexWap_day231.csv', header=None)\n#data = excelfilereader.iloc[0,:].values.tolist()\n#data = excelfilereader.iloc[0,:]*1000\n\n#excelfilereader=pd.read_csv(r'/kaggle/input/optiver-trading-at-the-close/train.csv')\n\nexcelfilereader=pd.read_csv(r'/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv')\n\ndef Data_input(test,stock,date,amplifier,dt=1):\n    data_sub=test[test['stock_id']==stock]\n    data_sub2=data_sub[data_sub['date_id']==date]\n    data=pd.DataFrame(data_sub2,columns=['wap'])\n    data = data.values.tolist()\n    data=np.squeeze(data)\n    data=data*amplifier\n    stock_series=data\n    time_series=range(0,data.shape[0])\n    df = pd.DataFrame({'dateindex': time_series, 'stock': stock_series})\n    x=df['dateindex']\n    y=df['stock']\n    x_sub = np.linspace(min(x), max(x), num=int(df.shape[0]/dt))\n    y_sub = pchip_interpolate(x, y, x_sub)\n    df_new = pd.DataFrame({'dateindex': x_sub, 'stock': y_sub})\n    return df_new\n\ndf_new=Data_input(excelfilereader,stock,date,amplifier)\nprint(range(min(excelfilereader['stock_id']),max(excelfilereader['stock_id'])))\nmake_figure(df_new['dateindex'], df_new['stock'],\n            title=\"Stock {} price at date {}\".format(int(stock), int(date)),\n            xtitle='Timesteps',\n            ytitle='Value'\n           )\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T01:13:52.694744Z","iopub.execute_input":"2023-11-21T01:13:52.696340Z","iopub.status.idle":"2023-11-21T01:13:52.889969Z","shell.execute_reply.started":"2023-11-21T01:13:52.696293Z","shell.execute_reply":"2023-11-21T01:13:52.888638Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"range(0, 199)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"96b0bb78-21a4-40b7-bc52-530eb78340d2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"96b0bb78-21a4-40b7-bc52-530eb78340d2\")) {                    Plotly.newPlot(                        \"96b0bb78-21a4-40b7-bc52-530eb78340d2\",                        [{\"x\":[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0,35.0,36.0,37.0,38.0,39.0,40.0,41.0,42.0,43.0,44.0,45.0,46.0,47.0,48.0,49.0,50.0,51.0,52.0,53.0,54.0],\"y\":[1000.0,999.8430000000001,999.771,999.479,999.338,999.4150000000001,999.9259999999999,1000.5269999999999,1000.777,1000.8649999999999,1001.1099999999999,1001.001,1000.886,1001.2149999999999,1001.1920000000001,1000.958,1000.043,999.829,1000.2260000000001,1000.2390000000001,1000.6330000000002,1000.6569999999999,1000.7090000000001,1000.556,1000.4599999999999,1000.1949999999999,999.8979999999999,999.859,1000.4980000000002,1000.4599999999999,999.95,1000.036,1000.437,1000.4399999999999,1000.464,1000.2009999999999,1000.248,1000.2599999999999,1000.1899999999999,1000.2059999999999,1000.284,1000.4599999999999,1000.665,1000.675,1000.839,1000.8399999999999,1000.5489999999999,1000.499,1000.1880000000001,1000.276,1000.3530000000001,1000.3100000000001,1000.3470000000001,1000.383,1000.2800000000001],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Stock 46 price at date 478\",\"x\":0.5,\"xanchor\":\"center\"},\"xaxis\":{\"title\":{\"text\":\"Timesteps\"},\"linecolor\":\"black\",\"linewidth\":1,\"mirror\":true},\"yaxis\":{\"title\":{\"text\":\"Value\"},\"linecolor\":\"black\",\"linewidth\":1,\"mirror\":true},\"showlegend\":false},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('96b0bb78-21a4-40b7-bc52-530eb78340d2');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"code","source":"index_1=[0,6,12,18,24,30,36,42,48,54]\nindex_2=[1,7,13,19,25,31,37,43,49]\nindex_3=[2,8,14,20,26,32,38,44,50]\nindex_4=[3,9,15,21,27,33,39,45,51]\nindex_5=[4,10,16,22,28,34,40,46,52]\nindex_6=[5,11,17,23,29,35,41,47,53]\nindex_list=[index_1,index_2,index_3,index_4,index_5, index_6]\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:51:22.082270Z","iopub.execute_input":"2023-11-21T00:51:22.083186Z","iopub.status.idle":"2023-11-21T00:51:22.094458Z","shell.execute_reply.started":"2023-11-21T00:51:22.083114Z","shell.execute_reply":"2023-11-21T00:51:22.092330Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def indexWAP(data, date, t):\n    coefficient = [0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.002,\n                   0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004, 0.002, 0.002, 0.004, 0.002,\n                   0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004, 0.004, 0.004, 0.006, 0.002, 0.002, 0.04,\n                   0.002, 0.002, 0.004, 0.04, 0.002, 0.001, 0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002,\n                   0.006, 0.004, 0.006, 0.004, 0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004,\n                   0.002, 0.004, 0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n                   0.02, 0.004, 0.006, 0.002, 0.02, 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02, 0.006, 0.001, 0.002,\n                   0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002, 0.004, 0.006, 0.006, 0.001, 0.04,\n                   0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002, 0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008,\n                   0.006, 0.004, 0.002, 0.006, 0.002, 0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008,\n                   0.006, 0.008, 0.002, 0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001,\n                   0.002, 0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002, 0.04,\n                   0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02, 0.004, 0.002, 0.006, 0.02, 0.001, 0.002, 0.006,\n                   0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04, 0.002, 0.008, 0.002, 0.004, 0.001,\n                   0.004, 0.006, 0.004]\n    date_sub = data.loc[(data[\"date_id\"] == date) & (data[\"seconds_in_bucket\"] == t)]\n    stk_id = pd.DataFrame(date_sub, columns=[\"stock_id\"])\n    wap = pd.DataFrame(date_sub, columns=[\"wap\"])\n    stk_id_arr = np.array(stk_id).reshape(-1)\n\n    missing_elemnts = [item for item in range(stk_id_arr[0], 200) if item not in stk_id_arr]\n    missing_elemnts_arr = np.array(missing_elemnts).reshape(-1)\n    list_coefficient = coefficient\n    for i in sorted(missing_elemnts_arr, reverse=True):\n        list_coefficient.pop(i)\n\n    norm = [float(i) / sum(list_coefficient) for i in list_coefficient]\n    stock_index = np.dot(norm, wap)\n    return (np.array([stock_index]).item())\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:51:22.097258Z","iopub.execute_input":"2023-11-21T00:51:22.098224Z","iopub.status.idle":"2023-11-21T00:51:22.124506Z","shell.execute_reply.started":"2023-11-21T00:51:22.098161Z","shell.execute_reply":"2023-11-21T00:51:22.123291Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"def Index_Calc(test,date):\n    time_arr = np.arange(0, 550,10)\n    time=np.arange(0,55)\n    date_0 = test.loc[(test[\"date_id\"] == date)]\n\n    index = []\n\n    for i in time_arr:\n        index.append(indexWAP(date_0, date, i))\n    index=np.squeeze(index)\n    index=index*amplifier\n    df_index = pd.DataFrame({'dateindex': time, 'stock': index})\n    return df_index\n\n#df_index=Index_Calc(date)\n#make_figure(df_index['dateindex'], df_index['stock'],\n#            title=\"Index at date {}\".format(int(date)),\n#            xtitle='Timesteps',\n#            ytitle='Value'\n#           )\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:51:22.128334Z","iopub.execute_input":"2023-11-21T00:51:22.128961Z","iopub.status.idle":"2023-11-21T00:51:22.144344Z","shell.execute_reply.started":"2023-11-21T00:51:22.128907Z","shell.execute_reply":"2023-11-21T00:51:22.142624Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def user_gen(df,start_trend=amplifier):\n    t=0\n    trend_index = start_trend\n    while t<=(df.shape[0]):\n        stock_price= df['stock'][t]\n        yield(t, stock_price, trend_index)\n        t+=1\n\ndef user_gen_dt(df,dt=1,start_trend=amplifier):\n    t=0\n    trend_index = start_trend\n    x=df['dateindex']\n    y=df['stock']\n    x_sub = np.linspace(min(x), max(x), num=int(df.shape[0]/dt))\n  #print(np.shape(x_sub))\n    y_sub = pchip_interpolate(x, y, x_sub)\n  #print(np.shape(y_sub))\n    while t<=int(len(x_sub)/dt):\n        stock_price= y_sub[t]\n        yield(t, stock_price, trend_index)\n        t+=dt\n\ndef user_sub(df,index_sub,start_trend=amplifier):\n    t=0\n    trend_index = start_trend\n    x=range(len(index_sub))\n    y=[]\n    #x=df['dateindex'][index_sub]\n    y=df['stock'][index_sub]\n    for i in range(len(index_sub)):\n        y[i]=df['stock'][index_sub[i]]\n    while t<=int(len(x)):\n        stock_price= y[t]\n        yield(t, stock_price, trend_index)\n        t+=1","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:51:22.148080Z","iopub.execute_input":"2023-11-21T00:51:22.148562Z","iopub.status.idle":"2023-11-21T00:51:22.162875Z","shell.execute_reply.started":"2023-11-21T00:51:22.148526Z","shell.execute_reply":"2023-11-21T00:51:22.160978Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def market_gen(gen, lag=1):\n\n    buffer = []\n    diffbuffer = []\n\n\n    # fill buffer\n    dt, last, trend = next(gen)\n    for i in range(lag):\n        prev = last\n        dt, last, trend = next(gen)\n        buffer.append(last-trend)\n        diffbuffer.append(last-prev)\n\n    # yield first group of lag vals and diffs\n    yield buffer+diffbuffer\n\n    while(True):\n        prev = last\n        dt, last, trend = next(gen)\n        buffer.pop(0)\n        buffer.append(last-trend)\n        diffbuffer.pop(0)\n        diffbuffer.append(last-prev)\n        yield buffer+diffbuffer\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:51:22.185986Z","iopub.execute_input":"2023-11-21T00:51:22.187011Z","iopub.status.idle":"2023-11-21T00:51:22.197686Z","shell.execute_reply.started":"2023-11-21T00:51:22.186948Z","shell.execute_reply":"2023-11-21T00:51:22.195463Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class Market:\n    \"\"\"Follows OpenAI gym environment convention basically\n    init with generator and number of stocks\n    reset() - generate and return first state\n    step() - generate next state and reward\n    \"\"\"\n    def __init__(self, gen, lag=16, nstocks=1, episode_length=300):\n        self.genfunc = gen\n        self.nstocks = nstocks\n        self.episode_length = episode_length\n        self.t = 0\n        self.total_reward = 0\n        self.lag = lag\n        self.observation_space = np.asarray([1] * nstocks * lag * 2,)\n        self.state_size = nstocks * lag * 2\n        self.action_size = 2\n\n    def reset(self):\n        self.t = 0\n        self.total_reward = 0\n        self.gen = [self.genfunc() for _ in range(self.nstocks)]\n        self.state=[next(g) for g in self.gen]\n        self.state = np.asarray([s for s in self.state])\n        return self.state\n\n    def render(self):\n        print(self.state[0, nstocks-1])\n\n    def step(self, action):\n        action = np.asarray([action])\n        try:\n            self.state=[next(g) for g in self.gen]\n        except StopIteration:\n            return print(\"generator failed.\\n\")\n        \n        self.state = np.asarray([s for s in self.state])\n        # last element is most recent change\n        stock_delta = np.asarray([s[-1] for s in self.state])\n        # element at lag-1 is most recent deviation\n        market_price = np.asarray([s[self.lag-1]+100 for s in self.state])\n        # map actions 0 1 2 to positions -1, 0, 1\n        position = action - 1\n        reward = position @ stock_delta\n        self.total_reward += reward\n        self.t += 1\n        done = True if self.episode_length and self.t >= self.episode_length else False\n        # state, reward, done, info\n        return self.state, reward, done, market_price\n\n    def close(self):\n        pass\n\n\n#env = Market(user_gen_dt(df,0.1), lag=1, nstocks=1, episode_length=10)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:51:22.238230Z","iopub.execute_input":"2023-11-21T00:51:22.238832Z","iopub.status.idle":"2023-11-21T00:51:22.258653Z","shell.execute_reply.started":"2023-11-21T00:51:22.238791Z","shell.execute_reply":"2023-11-21T00:51:22.257103Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"DISCOUNT_RATE = 0\n# WIN_REWARD = 10\nEPSILON_DECAY = 0.995\nSAMPLE_SIZE = 256\nRENDER = False\nOUTPUT_DIR = 'model_output/trading/'\n\nclass DQN_Agent:\n    def __init__(self, state_size, action_size, filename=\"dqn\",\n                 discount_rate=DISCOUNT_RATE,\n                 learning_rate=0.001,\n                 epsilon=1.0,\n                 epsilon_decay=EPSILON_DECAY,\n                 epsilon_min=0.01):\n\n        self.state_size = state_size\n        self.action_size = action_size\n        self.filename = filename\n        self.discount_rate = discount_rate\n        self.epsilon = epsilon\n        self.epsilon_decay = epsilon_decay\n        self.epsilon_min = epsilon_min\n        self.learning_rate = learning_rate\n\n        self.model = self.build_model()\n        self.memory = pd.DataFrame(columns=[\"state\", \"action\", \"next_state\",\n                                            \"reward\", \"done\"])\n        self.memory_size = 100000\n        self.results = []\n        self.train_batch_size = 1\n        self.timestep = 0\n        self.save_interval = 10\n\n    def build_model(self,\n                    n_hidden_layers=2,\n                    hidden_layer_size=16,\n                    activation='relu',\n                    reg_penalty=0.001,\n                    dropout=0.0675,\n                    verbose=True\n                   ):\n        \"\"\"return keras NN model per inputs\n        input is a state - array of size state_size\n        output is an array of action values - array of size action_size\n        \"\"\"\n\n        inputs = Input(shape=(self.state_size,), name=\"Input\")\n        last_layer = inputs\n\n        for i in range(n_hidden_layers):\n            if verbose:\n                formatstr = \"layer %d size %d, %s, reg_penalty %.8f, dropout %.3f\"\n                print(formatstr % (i + 1,\n                                   hidden_layer_size,\n                                   activation,\n                                   reg_penalty,\n                                   dropout))\n            # add dropout, but not on inputs, only between hidden layers\n            if i and dropout:\n                last_layer = Dropout(dropout, name=\"Dropout%02d\" % i)(last_layer)\n\n            last_layer = Dense(units=hidden_layer_size,\n                               activation=activation,\n                               kernel_initializer=glorot_uniform(),\n                               kernel_regularizer=l2(reg_penalty),\n                               name=\"Dense%02d\" % i)(last_layer)\n\n        outputs = Dense(self.action_size, activation='linear', name=\"Output\")(last_layer)\n\n        #model = Model(inputs=input_layer , output=last_layer)\n        model = Model(inputs=inputs, outputs=outputs)\n\n        if verbose:\n            print(model.summary())\n\n        model.compile(loss='mse', optimizer=Adam(\n            #learning_rate=self.learning_rate\n        ))\n\n        return model\n\n    def remember(self):\n        \"\"\"store the states and rewards needed to fit the model\"\"\"\n        # append in place\n        self.memory.loc[self.memory.shape[0]] = [self.state,\n                                                 self.action,\n                                                 self.next_state,\n                                                 self.reward,\n                                                 self.done]\n\n    def train(self):\n        \"\"\"train the model on experience stored by remember\"\"\"\n\n        # need at least SAMPLE_SIZE observations\n        if self.memory.shape[0] < SAMPLE_SIZE:\n            return\n\n        # truncate memory\n        self.memory = self.memory[-self.memory_size:]\n        # sample sample_size observations from memory\n        minibatch = self.memory.sample(n=SAMPLE_SIZE)\n\n        # target is our best estimate of value of each action\n        X_fit = np.concatenate(minibatch['state'].values)\n        X_fit = X_fit.reshape((SAMPLE_SIZE, self.state_size))\n        Y_pred = self.model.predict(X_fit)\n\n        # we don't just fit model against model's own prediction, gets us nowhere\n        # we improve the target by what we learned about the action we actually took\n        # value is reward obtained + predicted value of the observed next state\n        minibatch['target_observed'] = minibatch['reward']\n        # if done, target is the reward\n        # reward by gym env is only 1 for each timestep of survival\n        # but we also added a reward of -10 on failure\n        # if not done, add discount_rate  * Q-value prediction for  observed next state\n        not_done = minibatch.loc[minibatch['done'] == False]\n        X_observed = np.concatenate(not_done['next_state'].values)\n        X_observed = X_observed.reshape((not_done.shape[0], self.state_size))\n        # run all predictions at once\n        # iterates faster but does not train after each prediction\n        y_observed_pred = np.amax(self.model.predict(X_observed), axis=1)\n        minibatch.loc[minibatch['done'] == False, 'target_observed'] \\\n            += self.discount_rate * y_observed_pred\n        # vectorized vlookup - update col specified by action with target_observed\n        np.put_along_axis(Y_pred,\n                          minibatch['action'].astype(int).values.reshape(SAMPLE_SIZE, 1),\n                          minibatch['target_observed'].values.reshape(SAMPLE_SIZE, 1),\n                          axis=1)\n        # fit model against improved target\n        # arbitrary 8 batch size to reduce variance a little and speed up fit\n        self.model.fit(X_fit, Y_pred,\n                       epochs=1,\n                       batch_size=self.train_batch_size,\n                       verbose=0)\n\n        if self.epsilon > self.epsilon_min:\n            self.epsilon *= self.epsilon_decay\n\n    def act(self, state):\n        \"\"\"pick an action using model\"\"\"\n        if np.random.rand() <= self.epsilon:\n            return random.randrange(self.action_size)\n        act_values = self.model.predict(state)\n        return np.argmax(act_values[0])\n\n    def save(self):\n        \"save agent: pickle self and use Keras native save model\"\n        fullname = \"%s%s%05d\" % (OUTPUT_DIR, self.filename, len(self.results))\n        self.model.save(\"%s.h5\" % fullname)\n        pickle.dump(self, open(\"%s.p\" % fullname, \"wb\"))\n\n    def load(filename):\n        \"load saved agent\"\n        new = pickle.load(open(\"%s.p\" % filename, \"rb\"))\n        new.model = load_model(\"%s.h5\" % filename)\n        print(\"loaded %d results, %d rows of memory, epsilon %.4f\" % (len(new.results),\n                                                                      len(new.memory),\n                                                                      new.epsilon))\n        return new\n\n    def reset(self):\n        \"\"\"reset agent for start of episode\"\"\"\n        self.timestep = 0\n        self.total_reward = 0\n\n    def increment_time(self):\n        \"\"\"increment timestep counter\"\"\"\n        self.timestep += 1\n\n    def save_score(self):\n        \"\"\"save score of each episode\"\"\"\n        self.results.append(self.total_reward)\n\n    def score_episode(self, episode_num, n_episodes):\n        \"\"\"output results and save\"\"\"\n        self.save_score()\n        avglen = min(len(self.results), self.save_interval)\n        formatstr = \"{} episode {}/{}:, score: {}, {}-episode avg: {:.1f} Memory: {}        \"\n        print(formatstr.format(time.strftime(\"%H:%M:%S\"), len(self.results),\n                               n_episodes, self.total_reward, avglen,\n                               sum(self.results[-avglen:])/avglen, memusage()),\n              end=\"\\r\", flush=False)\n\n    def run_episode(self, render=RENDER):\n        \"\"\"run a full episode\"\"\"\n        global env\n\n        self.reset()\n        self.state = env.reset()\n        self.done = False\n\n        while not self.done:\n            if render:\n                env.render()\n            self.action = self.act(self.state.reshape([1, self.state_size]))\n            self.next_state, self.reward, self.done, _ = env.step(self.action)\n            self.total_reward += self.reward\n            self.remember()\n            self.state = self.next_state\n            self.increment_time()\n\n        if render:\n            env.render()\n\n        self.train()\n\n    def rlplot(self, title='Agent Training Progress'):\n        \"\"\"plot training progress\"\"\"\n        df = pd.DataFrame({'timesteps': self.results})\n        df['avg'] = df['timesteps'].rolling(10).mean()\n\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(x=df.index,\n                                 y=df['timesteps'],\n                                 mode='markers',\n                                 name='timesteps',\n                                 marker=dict(\n                                     color='mediumblue',\n                                     size=4,\n                                 ),\n                                ))\n\n        fig.add_trace(go.Scatter(x=df.index,\n                                 y=df['avg'],\n                                 mode='lines',\n                                 line_width=3,\n                                 name='moving average'))\n\n        fig.update_layout(\n            title=dict(text=title,\n                       x=0.5,\n                       xanchor='center'),\n            xaxis=dict(\n                title=\"Episodes\",\n                linecolor='black',\n                linewidth=1,\n                mirror=True\n            ),\n            yaxis=dict(\n                title=\"Total Reward per Episode\",\n                linecolor='black',\n                linewidth=1,\n                mirror=True\n            ),\n            legend=go.layout.Legend(\n                x=0.01,\n                y=0.99,\n                traceorder=\"normal\",\n                font=dict(\n                    family=\"sans-serif\",\n                    size=12,\n                    color=\"black\"\n                ),\n                #bgcolor=\"LightSteelBlue\",\n                bordercolor=\"Black\",\n                borderwidth=1,\n            ),\n        )\n\n        return fig.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:51:22.300904Z","iopub.execute_input":"2023-11-21T00:51:22.301748Z","iopub.status.idle":"2023-11-21T00:51:22.350281Z","shell.execute_reply.started":"2023-11-21T00:51:22.301705Z","shell.execute_reply":"2023-11-21T00:51:22.348803Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"RENDER = False\nOUTPUT_DIR = 'model_output/trading/'\n\nclass Agent:\n    \"\"\"abstract base class for agents\"\"\"\n\n    def __init__(self, state_size, action_size, filename=\"model\",\n                 *args, **kwargs):\n        self.state_size = state_size\n        self.action_size = action_size\n        self.filename = filename\n        self.timestep = 0\n        self.total_reward = 0\n        self.save_interval = 10\n\n        raise NotImplementedError\n\n    def build_model(self, *args, **kwargs):\n        \"\"\"build the relevant model\"\"\"\n        raise NotImplementedError\n\n    def reset(self):\n        \"\"\"reset agent for start of episode\"\"\"\n        self.timestep = 0\n        self.total_reward = 0\n\n    def increment_time(self):\n        \"\"\"increment timestep counter\"\"\"\n        self.timestep += 1\n\n    def remember(self, *args, **kwargs):\n        \"\"\"store the states and rewards needed to fit the model\"\"\"\n        raise NotImplementedError\n\n    def train(self, *args, **kwargs):\n        \"\"\"train the model on experience stored by remember\"\"\"\n        raise NotImplementedError\n\n    def act(self, *args, **kwargs):\n        \"\"\"pick an action using model\"\"\"\n        raise NotImplementedError\n\n    def save_score(self):\n        \"\"\"save score of each episode\"\"\"\n        self.results.append(self.total_reward)\n\n    def score_episode(self, episode_num, n_episodes):\n        \"\"\"output results and save\"\"\"\n        self.save_score()\n        avglen = min(len(self.results), self.save_interval)\n        formatstr = \"{} episode {}/{}:, score: {}, {}-episode avg: {:.1f} Memory: {}        \"\n        print(formatstr.format(time.strftime(\"%H:%M:%S\"), len(self.results),\n                               n_episodes, self.total_reward, avglen,\n                               sum(self.results[-avglen:])/avglen, memusage()),\n              end=\"\\r\", flush=False)\n\n    def run_episode(self, render=RENDER):\n        \"\"\"run a full episode\"\"\"\n        global env\n\n        self.reset()\n        self.state = env.reset()\n        self.done = False\n\n        while not self.done:\n            if render:\n                env.render()\n            self.action = self.act(self.state.reshape([1, self.state_size]))\n            self.next_state, self.reward, self.done, _ = env.step(self.action)\n            self.total_reward += self.reward\n\n            self.remember()\n            self.state = self.next_state\n            self.increment_time()\n\n        if render:\n            env.render()\n\n        self.train()\n\n    def save(self, *args, **kwargs):\n        \"\"\"save agent to disk\"\"\"\n        raise NotImplementedError\n\n    def load(*args, **kwargs):\n        \"\"\"load agent from disk\"\"\"\n        raise NotImplementedError\n\n    def view(self):\n        \"\"\"Run an episode without training, with rendering\"\"\"\n        state = env.reset()\n        state = np.reshape(state, [1, self.state_size])\n        done = False\n\n        # run an episode\n        self.timestep = 0\n        r = 0\n        while not done:\n            env.render()\n            action = self.act(state)\n            lastmarket = self.state[0, nstocks-1]\n            state, reward, done, _ = env.step(action)\n            newmarket = self.state[0, nstocks-1]\n            print(\"prev mkt: %.4f action: %d, new mkt %f, reward %f\" % (lastmarket, action, newmarket, reward))\n            r += reward\n            state = np.reshape(state, [1, self.state_size])\n            self.timestep += 1\n        env.render()\n        print(r)\n        env.close()\n        return self.timestep\n\n    def rlplot(self, title='Trading Agent Training Progress'):\n        \"\"\"plot training progress\"\"\"\n        df = pd.DataFrame({'timesteps': self.results})\n        df['avg'] = df['timesteps'].rolling(10).mean()\n\n        fig = go.Figure()\n        fig.add_trace(go.Scatter(x=df.index,\n                                 y=df['timesteps'],\n                                 mode='markers',\n                                 name='timesteps',\n                                 marker=dict(\n                                     color='mediumblue',\n                                     size=4,\n                                 ),\n                                ))\n\n        fig.add_trace(go.Scatter(x=df.index,\n                                 y=df['avg'],\n                                 mode='lines',\n                                 line_width=3,\n                                 name='moving average'))\n\n        fig.update_layout(\n            title=dict(text=title,\n                       x=0.5,\n                       xanchor='center'),\n            xaxis=dict(\n                title=\"Episodes\",\n                linecolor='black',\n                linewidth=1,\n                mirror=True\n            ),\n            yaxis=dict(\n                title=\"Total Reward per Episode\",\n                linecolor='black',\n                linewidth=1,\n                mirror=True\n            ),\n            legend=go.layout.Legend(\n                x=0.01,\n                y=0.99,\n                traceorder=\"normal\",\n                font=dict(\n                    family=\"sans-serif\",\n                    size=12,\n                    color=\"black\"\n                ),\n                #bgcolor=\"LightSteelBlue\",\n                bordercolor=\"Black\",\n                borderwidth=1,\n            ),\n        )\n\n        return fig.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:51:22.428177Z","iopub.execute_input":"2023-11-21T00:51:22.428818Z","iopub.status.idle":"2023-11-21T00:51:22.460413Z","shell.execute_reply.started":"2023-11-21T00:51:22.428769Z","shell.execute_reply":"2023-11-21T00:51:22.458683Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"class REINFORCE_Agent(Agent):\n    \"\"\"REINFORCE policy gradient method using deep Keras NN\"\"\"\n    def __init__(self, state_size=4, action_size=2, learning_rate=0.005,\n                 discount_rate=DISCOUNT_RATE, n_hidden_layers=2, hidden_layer_size=16,\n                 activation='relu', reg_penalty=0, dropout=0, filename=\"kreinforce\",\n                 verbose=True):\n        self.state_size = state_size\n        self.action_size = action_size\n        self.action_space = list(range(action_size))\n        self.learning_rate = learning_rate\n        self.discount_rate = discount_rate\n\n        self.n_hidden_layers = n_hidden_layers\n        self.hidden_layer_size = hidden_layer_size\n        self.activation = activation\n        self.reg_penalty = reg_penalty\n        self.dropout = dropout\n        self.verbose = verbose\n        self.filename = filename\n\n        self.train_model, self.predict_model = self.policy_model()\n        self.results = []\n        self.save_interval = 10\n        self.reset()\n\n\n    def reset(self):\n        \"\"\"reset agent for start of episode\"\"\"\n        self.timestep = 0\n        # truncate memory\n        self.state_memory = []\n        self.action_memory = []\n        self.reward_memory = []\n        self.total_reward = 0\n\n    def policy_model(self):\n        \"\"\"set up NN model for policy.\n        predict returns probs of actions to sample from.\n        train needs discounted rewards for the episode, so we define custom loss.\n        when training use train_model with custom loss and multi input of training data and rewards.\n        when predicting use predict_model with single input.\n        \"\"\"\n\n        def custom_loss(y_true, y_pred):\n            y_pred_clip = K.clip(y_pred, 1e-8, 1-1e-8)\n            log_likelihood = y_true*K.log(y_pred_clip)\n            return K.sum(-log_likelihood*discounted_rewards)\n\n        inputs = Input(shape=(self.state_size,), name=\"Input\")\n        discounted_rewards = Input(shape=(1,), name=\"Discounted_rewards\")\n        last_layer = inputs\n\n        for i in range(self.n_hidden_layers):\n            if self.verbose:\n                formatstr = \"layer %d size %d, %s, reg_penalty %.8f, dropout %.3f\"\n                print(formatstr % (i + 1,\n                                   self.hidden_layer_size,\n                                   self.activation,\n                                   self.reg_penalty,\n                                   self.dropout,\n                                   ))\n            # add dropout, but not on inputs, only between hidden layers\n            if i and self.dropout:\n                last_layer = Dropout(self.dropout, name=\"Dropout%02d\" % i)(last_layer)\n\n            last_layer = Dense(units=self.hidden_layer_size,\n                               activation=self.activation,\n                               kernel_initializer=glorot_uniform(),\n                               kernel_regularizer=keras.regularizers.l2(self.reg_penalty),\n                               name=\"Dense%02d\" % i)(last_layer)\n\n        outputs = Dense(self.action_size, activation='softmax', name=\"Output\")(last_layer)\n\n        train_model = Model(inputs=[inputs, discounted_rewards], outputs=[outputs])\n        train_model.compile(optimizer=Adam(lr=self.learning_rate), loss=custom_loss)\n\n        predict_model = Model(inputs=[inputs], outputs=[outputs])\n\n        if self.verbose:\n            print(predict_model.summary())\n\n        return train_model, predict_model\n\n\n    def act(self, state):\n        \"\"\"pick an action using predict_model\"\"\"\n        probabilities = self.predict_model.predict(state)\n\n        action = np.random.choice(self.action_space, p=probabilities[0])\n        prob=probabilities[0][action]\n        #print(\"probability={}\\n\".format(probabilities[0][action]))\n        return action\n\n    def remember(self):\n        \"\"\"at each step save state, action, reward for future training\"\"\"\n\n        self.state_memory.append(self.state)\n        self.action_memory.append(self.action)\n        self.reward_memory.append(self.reward)\n        \n\n    def train(self):\n        \"\"\"train the model on experience stored by remember\"\"\"\n        state_memory = np.array(self.state_memory)\n        state_memory = state_memory.reshape((len(self.state_memory),self.state_size))\n        action_memory = np.array(self.action_memory)\n        reward_memory = np.array(self.reward_memory)\n\n        # one-hot actions\n        actions = np.zeros([len(action_memory), self.action_size])\n        actions[np.arange(len(action_memory)), action_memory] = 1\n\n        disc_rewards = np.zeros_like(reward_memory)\n        cumulative_rewards = 0\n        for i in reversed(range(len(reward_memory))):\n            cumulative_rewards = cumulative_rewards * self.discount_rate + reward_memory[i]\n            disc_rewards[i] = cumulative_rewards\n\n        # standardize\n        disc_rewards -= np.mean(disc_rewards)\n        disc_rewards /= np.std(disc_rewards) if np.std(disc_rewards) > 0 else 1\n\n        # train states v. actions, (complemented by disc_rewards_std)\n        cost = self.train_model.train_on_batch([state_memory, disc_rewards], actions)\n\n        return cost\n\n    def view(self):\n        \"\"\"Run an episode without training, with rendering\"\"\"\n        state = env.reset()\n        state = np.reshape(state, [1, self.state_size])\n        done = False\n\n        # run an episode\n        self.timestep = 0\n        r = 0\n        retarray = []\n        while not done:\n            action = self.act(state)\n            lastmarket = state[0, self.state_size//2-1]\n            state, reward, done, _ = env.step(action)\n            newmarket = state[0, self.state_size//2-1]\n            print(\"prev mkt: %.4f action: %d, new mkt %.4f, reward %f\" % (lastmarket, action, newmarket, reward))\n            r += reward\n            state = np.reshape(state, [1, self.state_size])\n            self.timestep += 1\n            retarray.append((self.timestep, action, lastmarket, newmarket, reward))\n        print(r)\n        env.close()\n        return retarray\n\n    def save(self):\n        \"save agent: pickle self and use Keras native save model\"\n        fullname = \"%s%s%05d\" % (OUTPUT_DIR, self.filename, len(self.results))\n        self.predict_model.save(\"%s_predict.h5\" % fullname)\n        # can't save / load train model due to custom loss\n        pickle.dump(self, open(\"%s.p\" % fullname, \"wb\"))\n\n    def load(filename, memory=True):\n        \"load saved agent\"\n        self = pickle.load(open(\"%s.p\" % filename, \"rb\"))\n        self.predict_model = load_model(\"%s_predict.h5\" % filename)\n        print(\"loaded %d results, %d rows of memory, epsilon %.4f\" % (len(self.results),\n                                                                      len(self.memory),\n                                                                      self.epsilon))","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:51:22.464655Z","iopub.execute_input":"2023-11-21T00:51:22.465802Z","iopub.status.idle":"2023-11-21T00:51:22.509333Z","shell.execute_reply.started":"2023-11-21T00:51:22.465742Z","shell.execute_reply":"2023-11-21T00:51:22.507457Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dt=1\n#index_1=[0,6,12,18,24,30,36,42,48,54]\n#index_2=[1,7,13,19,25,31,37,43,49]\n#index_3=[2,8,14,20,26,32,38,44,50]\n#index_4=[3,9,15,21,27,33,39,45,51]\n#index_5=[4,10,16,22,28,34,40,46,52]\n#index_6=[5,11,17,23,29,35,41,47,53]\n\n#index_pick=index_5\nN_EPISODES = 500\n#lag is fixed\nlag = 1\n#ticks_per_episode = len(index_pick)/dt-1-lag\nnstocks = 1\n\n\n#gen = user_sub(df_new,index_1,start_trend=amplifier)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:51:22.512110Z","iopub.execute_input":"2023-11-21T00:51:22.512634Z","iopub.status.idle":"2023-11-21T00:51:22.528255Z","shell.execute_reply.started":"2023-11-21T00:51:22.512587Z","shell.execute_reply":"2023-11-21T00:51:22.526818Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"#def shm_market_gen():\n#    return market_gen(gen=user_sub(df_new,index_pick,start_trend=amplifier),\n#                      lag=lag)\n\n\n#gen=shm_market_gen()\n#time_series=[]\n#stock_series=[]\n#for i in range(len(index_pick)-lag):\n#    z = next(gen)\n#    time_series.append(i)\n#    stock_series.append(z[1])\n\n#df_gen = pd.DataFrame({'dateindex': time_series, 'stock': stock_series})\n\n#make_figure(df_gen['dateindex'], df_gen['stock'],\n#            title='Genarated market',\n#            xtitle='Timesteps',\n#            ytitle='buffer+diffbuffer'\n#           )","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:51:22.535528Z","iopub.execute_input":"2023-11-21T00:51:22.536186Z","iopub.status.idle":"2023-11-21T00:51:22.547683Z","shell.execute_reply.started":"2023-11-21T00:51:22.536152Z","shell.execute_reply":"2023-11-21T00:51:22.546346Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"test=pd.read_csv(r'/kaggle/input/optiver-trading-at-the-close/example_test_files/test.csv')\n\n\ndate=478\nstock=46\ndf_new=Data_input(test,stock,date,amplifier)\n\n#ticks_per_episode = len(index_pick)/dt-1-lag\nnstocks = 1\nresult_index=[]\ndf_index=Index_Calc(test,date)\nfor i in range(len(index_list)):\n    ticks_per_episode = len(index_list[i])/dt-1-lag\n    def shm_market_gen():\n        return market_gen(gen=user_sub(df_index,index_list[i],start_trend=amplifier),lag=1)\n    env = Market(shm_market_gen,\n             lag=lag,\n             nstocks=1,\n             episode_length=ticks_per_episode)\n\n    agent = REINFORCE_Agent(state_size=nstocks*lag*2,\n                        action_size=3,\n                       )\n\n    start_time = time.time()\n    print(\"Start: %s\" % (time.strftime(\"%H:%M:%S\")))\n\n    for e in range(N_EPISODES):\n        agent.run_episode()\n        agent.score_episode(e, N_EPISODES)\n    \n\n    #if e and (e+1) % agent.save_interval == 0:\n    #    agent.save()\n\n    elapsed_time = time.time() - start_time\n    print(\"\\nTrain time: \", elapsed_time)\n    env.reset()\n    z = agent.view()\n\n    df = pd.DataFrame(z)\n    df.columns = [\"timestep\", \"action\", \"lastmarket\", \"newmarket\", \"reward\"]\n        #df['lastmarket']+=1\n        #df['newmarket']+=1\n        #df['short'] = np.nan\n        #df.loc[df['action']==0, 'short'] = df['newmarket']\n        #df['flat'] = np.nan\n        #df.loc[df['action']==1, 'flat'] = df['newmarket']\n        #df['long'] = np.nan\n        #df.loc[df['action']==2, 'long'] = df['newmarket']\n        #df['totalreward'] = df['reward'].cumsum()\n        #df.to_csv('df_index_list_{}.csv'.format(i))\n    prob=agent.predict_model.predict(agent.state_memory)\n    action = np.random.choice(agent.action_space, p=prob[0])\n    pick_index=np.array(df_index['stock'][index_list[i]])\n        #arr=np.array(df_index['stock'][index_list[i]])\n    mean_diff=np.mean(np.absolute(np.diff(pick_index)))\n    action_arr=np.array(df['action']-1)\n        \n    wap_future_index=[]\n    #assume in the first time index of t+60 the same as t\n    wap_future_index.append(pick_index[0])\n    for j in range(len(action_arr)):\n        wap_future_index.append(action_arr[j]*mean_diff+pick_index[j+1])\n    wap_future_index.append((action-1)*mean_diff+pick_index[-1])\n    seconds_in_bucket=[j * 10 for j in index_list[i]]\n    comb=list(zip(seconds_in_bucket,pick_index,wap_future_index))\n    result_index.append(comb)\n    \nresult_indx_list = list(chain.from_iterable(result_index))\n#print(result_indx_list)\nsorted_indx_result = sorted(result_indx_list, key=lambda x: x[0])\n#print(sorted_indx_result)\nseconds_in_bucket, wap_index, wap_index_future = zip(*sorted_indx_result)\n#seconds_in_bucket_list=list(seconds_in_bucket)\nwap_index_list=list(wap_index)\nwap_index_future_list=list(wap_index_future)\n\nresult=[]\n\nfor i in range(len(index_list)):\n    ticks_per_episode = len(index_list[i])/dt-1-lag\n    def shm_market_gen():\n        return market_gen(gen=user_sub(df_new,index_list[i],start_trend=amplifier),\n                      lag=1)\n\n    env = Market(shm_market_gen,\n             lag=lag,\n             nstocks=1,\n             episode_length=ticks_per_episode)\n\n    agent = REINFORCE_Agent(state_size=nstocks*lag*2,\n                        action_size=3,\n                       )\n\n    start_time = time.time()\n    print(\"Start: %s\" % (time.strftime(\"%H:%M:%S\")))\n\n    for e in range(N_EPISODES):\n        agent.run_episode()\n        agent.score_episode(e, N_EPISODES)\n    \n\n    #if e and (e+1) % agent.save_interval == 0:\n    #    agent.save()\n\n    elapsed_time = time.time() - start_time\n    print(\"\\nTrain time: \", elapsed_time)\n    env.reset()\n    z = agent.view()\n\n    df = pd.DataFrame(z)\n    df.columns = [\"timestep\", \"action\", \"lastmarket\", \"newmarket\", \"reward\"]\n    #df['lastmarket']+=1\n    #df['newmarket']+=1\n    #df['short'] = np.nan\n    #df.loc[df['action']==0, 'short'] = df['newmarket']\n    #df['flat'] = np.nan\n    #df.loc[df['action']==1, 'flat'] = df['newmarket']\n    #df['long'] = np.nan\n    #df.loc[df['action']==2, 'long'] = df['newmarket']\n    #df['totalreward'] = df['reward'].cumsum()\n    #df.to_csv('df_list_{}.csv'.format(i))\n    prob=agent.predict_model.predict(agent.state_memory)\n    action = np.random.choice(agent.action_space, p=prob[0])\n    pick_index=np.array(df_new['stock'][index_list[i]])\n    mean_diff=np.mean(np.absolute(np.diff(pick_index)))\n    action_arr=np.array(df['action']-1)\n    #pick_index=np.array(df_new['stock'][index_list[i]])\n    wap_future_index=[]\n    #assume in the first time index of t+60 the same as t\n    wap_future_index.append(pick_index[0])\n    for j in range(len(action_arr)):\n        wap_future_index.append(action_arr[j]*mean_diff+pick_index[j+1])\n    wap_future_index.append((action-1)*mean_diff+pick_index[-1])\n    seconds_in_bucket=[j * 10 for j in index_list[i]]\n    comb=list(zip(seconds_in_bucket,pick_index,wap_future_index))\n    result.append(comb)\nresult_list = list(chain.from_iterable(result))\n#print(result_list)\nsorted_result = sorted(result_list, key=lambda x: x[0])\n#print(sorted_result)\nseconds_in_bucket, wap, wap_future = zip(*sorted_result)\nseconds_in_bucket_list=list(seconds_in_bucket)\nwap_list=list(wap)\nwap_future_list=list(wap_future)\n#print(list(seconds_in_bucket))\n#print(list(wap))\n#print(list(wap_future))\ntarget_out=[]\nfor i in range(len(seconds_in_bucket_list)):\n    target_out.append((wap_future_list[i]/wap_list[i]-wap_index_future_list[i]/wap_index_list[i])*10000)\n    \nexcelfilereader=pd.read_csv(r'/kaggle/input/optiver-trading-at-the-close/example_test_files/revealed_targets.csv')\ndata_sub=excelfilereader[excelfilereader['stock_id']==stock]\ndata_sub2=data_sub[data_sub['revealed_date_id']==date]\ndata=pd.DataFrame(data_sub2,columns=['revealed_target'])\ndata = data.values.tolist()\ndata=np.squeeze(data)\n#print(data)\n\nplt.plot(data,label=\"truth\")\nplt.plot(target_out,label=\"Calculated\")\nplt.ylabel('Target')\nplt.title('Target of stock {} at date {}'.format(stock,date))\nplt.legend()\nplt.show()\n\nfrom sklearn.metrics import mean_absolute_error as mae\nerror = mae(data, target_out) \n\nprint(\"Mean absolute error : \" + str(error)) ","metadata":{"execution":{"iopub.status.busy":"2023-11-21T01:05:58.602706Z","iopub.execute_input":"2023-11-21T01:05:58.603339Z","iopub.status.idle":"2023-11-21T01:09:22.474729Z","shell.execute_reply.started":"2023-11-21T01:05:58.603293Z","shell.execute_reply":"2023-11-21T01:09:22.473475Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"layer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_51\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\nNone\nStart: 01:05:59\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"01:06:16 episode 500/500:, score: 2.415408000000866, 10-episode avg: 2.4 Memory: 788.9 KB            \nTrain time:  17.41446042060852\nprev mkt: 1.0869 action: 2, new mkt 1.3753, reward 0.288445\nprev mkt: 1.3753 action: 0, new mkt 0.7831, reward 0.592189\nprev mkt: 0.7831 action: 2, new mkt 1.1325, reward 0.349364\nprev mkt: 1.1325 action: 0, new mkt 0.4120, reward 0.720463\nprev mkt: 0.4120 action: 2, new mkt 0.4070, reward -0.005050\nprev mkt: 0.4070 action: 2, new mkt 0.8868, reward 0.479815\nprev mkt: 0.8868 action: 2, new mkt 1.1438, reward 0.256987\nprev mkt: 1.1438 action: 0, new mkt 1.4106, reward -0.266805\n2.415408000000866\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_53\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\nNone\nStart: 01:06:16\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"01:06:31 episode 500/500:, score: 2.3894960000000083, 10-episode avg: 2.4 Memory: 788.9 KB          \nTrain time:  15.127660512924194\nprev mkt: 1.4387 action: 2, new mkt 1.4476, reward 0.008884\nprev mkt: 1.4476 action: 0, new mkt 0.9719, reward 0.475623\nprev mkt: 0.9719 action: 2, new mkt 1.0910, reward 0.119049\nprev mkt: 1.0910 action: 0, new mkt 0.2583, reward 0.832733\nprev mkt: 0.2583 action: 2, new mkt 0.6808, reward 0.422542\nprev mkt: 0.6808 action: 2, new mkt 1.0839, reward 0.403097\nprev mkt: 1.0839 action: 2, new mkt 1.2115, reward 0.127568\n2.3894960000000083\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_55\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"None\nStart: 01:06:32\n01:06:47 episode 500/500:, score: 2.3563709999992852, 10-episode avg: 2.1 Memory: 788.9 KB          \nTrain time:  15.098436832427979\nprev mkt: 1.6056 action: 0, new mkt 1.4413, reward 0.164294\nprev mkt: 1.4413 action: 0, new mkt 0.9639, reward 0.477411\nprev mkt: 0.9639 action: 0, new mkt 0.9588, reward 0.005050\nprev mkt: 0.9588 action: 0, new mkt 0.1924, reward 0.766411\nprev mkt: 0.1924 action: 2, new mkt 0.6607, reward 0.468280\nprev mkt: 0.6607 action: 2, new mkt 1.1868, reward 0.526152\nprev mkt: 1.1868 action: 0, new mkt 1.2381, reward -0.051227\n2.3563709999992852\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_57\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\nNone\nStart: 01:06:47\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"01:07:02 episode 500/500:, score: 2.1421829999995907, 10-episode avg: 2.1 Memory: 789.1 KB          \nTrain time:  15.523731708526611\nprev mkt: 1.5710 action: 0, new mkt 1.2090, reward 0.361997\nprev mkt: 1.2090 action: 0, new mkt 1.1077, reward 0.101355\nprev mkt: 1.1077 action: 0, new mkt 0.9792, reward 0.128499\nprev mkt: 0.9792 action: 0, new mkt 0.2306, reward 0.748599\nprev mkt: 0.2306 action: 2, new mkt 0.7184, reward 0.487778\nprev mkt: 0.7184 action: 2, new mkt 1.1566, reward 0.438236\nprev mkt: 1.1566 action: 0, new mkt 1.2809, reward -0.124281\n2.1421829999995907\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_59\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\nNone\nStart: 01:07:03\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"01:07:20 episode 500/500:, score: 1.7486610000006522, 10-episode avg: 2.0 Memory: 794.6 KB          \nTrain time:  17.49977946281433\nprev mkt: 1.2884 action: 0, new mkt 0.7006, reward 0.587806\nprev mkt: 0.7006 action: 2, new mkt 1.1016, reward 0.401022\nprev mkt: 1.1016 action: 2, new mkt 0.9944, reward -0.107207\nprev mkt: 0.9944 action: 0, new mkt 0.5570, reward 0.437407\nprev mkt: 0.5570 action: 2, new mkt 0.6872, reward 0.130228\nprev mkt: 0.6872 action: 2, new mkt 1.0677, reward 0.380528\nprev mkt: 1.0677 action: 0, new mkt 1.3633, reward -0.295537\n1.5342470000008461\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_61\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\nNone\nStart: 01:07:20\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"01:07:37 episode 500/500:, score: 1.573694999999816, 10-episode avg: 1.6 Memory: 800.7 KB           \nTrain time:  17.01216697692871\nprev mkt: 1.2153 action: 0, new mkt 0.6253, reward 0.590052\nprev mkt: 0.6253 action: 2, new mkt 1.1916, reward 0.566294\nprev mkt: 1.1916 action: 0, new mkt 1.0193, reward 0.172283\nprev mkt: 1.0193 action: 0, new mkt 0.4650, reward 0.554270\nprev mkt: 0.4650 action: 2, new mkt 0.7779, reward 0.312851\nprev mkt: 0.7779 action: 0, new mkt 1.1098, reward -0.331877\nprev mkt: 1.1098 action: 0, new mkt 1.3999, reward -0.290178\n1.573694999999816\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_63\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"None\nStart: 01:07:37\n01:07:55 episode 500/500:, score: 3.6479999999993424, 10-episode avg: 3.6 Memory: 806.0 KB         \nTrain time:  17.75866389274597\nprev mkt: -0.0740 action: 2, new mkt 0.8860, reward 0.960000\nprev mkt: 0.8860 action: 0, new mkt 0.2260, reward 0.660000\nprev mkt: 0.2260 action: 2, new mkt 0.4600, reward 0.234000\nprev mkt: 0.4600 action: 2, new mkt -0.0500, reward -0.510000\nprev mkt: -0.0500 action: 2, new mkt 0.2480, reward 0.298000\nprev mkt: 0.2480 action: 2, new mkt 0.6650, reward 0.417000\nprev mkt: 0.6650 action: 0, new mkt 0.1880, reward 0.477000\nprev mkt: 0.1880 action: 2, new mkt 0.2800, reward 0.092000\n2.627999999999588\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_65\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\nNone\nStart: 01:07:55\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"01:08:12 episode 500/500:, score: 2.542999999999779, 10-episode avg: 2.7 Memory: 809.7 KB          \nTrain time:  16.42613673210144\nprev mkt: 0.5270 action: 2, new mkt 1.2150, reward 0.688000\nprev mkt: 1.2150 action: 0, new mkt 0.2390, reward 0.976000\nprev mkt: 0.2390 action: 1, new mkt 0.1950, reward 0.000000\nprev mkt: 0.1950 action: 0, new mkt 0.0360, reward 0.159000\nprev mkt: 0.0360 action: 1, new mkt 0.2600, reward 0.000000\nprev mkt: 0.2600 action: 2, new mkt 0.6750, reward 0.415000\nprev mkt: 0.6750 action: 0, new mkt 0.2760, reward 0.399000\n2.63699999999983\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_67\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"None\nStart: 01:08:12\n01:08:28 episode 500/500:, score: 2.8000000000004093, 10-episode avg: 2.8 Memory: 817.4 KB           \nTrain time:  16.36633324623108\nprev mkt: 0.7770 action: 0, new mkt 1.1920, reward -0.415000\nprev mkt: 1.1920 action: 0, new mkt 0.6330, reward 0.559000\nprev mkt: 0.6330 action: 0, new mkt -0.1020, reward 0.735000\nprev mkt: -0.1020 action: 2, new mkt 0.4370, reward 0.539000\nprev mkt: 0.4370 action: 0, new mkt 0.1900, reward 0.247000\nprev mkt: 0.1900 action: 2, new mkt 0.8390, reward 0.649000\nprev mkt: 0.8390 action: 0, new mkt 0.3530, reward 0.486000\n2.8000000000004093\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_69\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\nNone\nStart: 01:08:28\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"01:08:45 episode 500/500:, score: 2.9849999999996726, 10-episode avg: 3.0 Memory: 823.3 KB          \nTrain time:  16.63254690170288\nprev mkt: 0.8650 action: 0, new mkt 0.9580, reward -0.093000\nprev mkt: 0.9580 action: 0, new mkt 0.6570, reward 0.301000\nprev mkt: 0.6570 action: 0, new mkt -0.1410, reward 0.798000\nprev mkt: -0.1410 action: 2, new mkt 0.4400, reward 0.581000\nprev mkt: 0.4400 action: 0, new mkt 0.2060, reward 0.234000\nprev mkt: 0.2060 action: 2, new mkt 0.8400, reward 0.634000\nprev mkt: 0.8400 action: 0, new mkt 0.3100, reward 0.530000\n2.9849999999996726\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_71\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"None\nStart: 01:08:45\n01:09:03 episode 500/500:, score: 2.556999999999448, 10-episode avg: 2.6 Memory: 829.0 KB         \nTrain time:  18.115593433380127\nprev mkt: 1.1100 action: 0, new mkt 0.0430, reward 1.067000\nprev mkt: 0.0430 action: 2, new mkt 0.7090, reward 0.666000\nprev mkt: 0.7090 action: 0, new mkt 0.4980, reward 0.211000\nprev mkt: 0.4980 action: 0, new mkt 0.4640, reward 0.034000\nprev mkt: 0.4640 action: 0, new mkt 0.2840, reward 0.180000\nprev mkt: 0.2840 action: 1, new mkt 0.5490, reward 0.000000\nprev mkt: 0.5490 action: 0, new mkt 0.3470, reward 0.202000\n2.3599999999997863\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_73\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"None\nStart: 01:09:04\n01:09:22 episode 500/500:, score: 2.5900000000001455, 10-episode avg: 2.5 Memory: 834.8 KB          \nTrain time:  17.9643394947052\nprev mkt: 1.0010 action: 0, new mkt -0.1710, reward 1.172000\nprev mkt: -0.1710 action: 2, new mkt 0.5560, reward 0.727000\nprev mkt: 0.5560 action: 0, new mkt 0.4600, reward 0.096000\nprev mkt: 0.4600 action: 0, new mkt 0.2010, reward 0.259000\nprev mkt: 0.2010 action: 2, new mkt 0.4600, reward 0.259000\nprev mkt: 0.4600 action: 0, new mkt 0.4990, reward -0.039000\nprev mkt: 0.4990 action: 0, new mkt 0.3830, reward 0.116000\n2.5900000000001455\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"Mean absolute error : 3.734589105507396\n","output_type":"stream"}]},{"cell_type":"code","source":"\nexcelfilereader=pd.read_csv(r'/kaggle/input/optiver-trading-at-the-close/example_test_files/revealed_targets.csv')\ndate=478\nstock=46\n\n\n#ticks_per_episode = len(index_pick)/dt-1-lag\nnstocks = 1\nresult_index=[]\ndf_index=Index_Calc(test,date)\nfor i in range(len(index_list)):\n    ticks_per_episode = len(index_list[i])/dt-1-lag\n    def shm_market_gen():\n        return market_gen(gen=user_sub(df_index,index_list[i],start_trend=amplifier),lag=1)\n    env = Market(shm_market_gen,\n             lag=lag,\n             nstocks=1,\n             episode_length=ticks_per_episode)\n\n    agent = REINFORCE_Agent(state_size=nstocks*lag*2,\n                        action_size=3,\n                       )\n\n    start_time = time.time()\n    print(\"Start: %s\" % (time.strftime(\"%H:%M:%S\")))\n\n    for e in range(N_EPISODES):\n        agent.run_episode()\n        agent.score_episode(e, N_EPISODES)\n    \n\n    #if e and (e+1) % agent.save_interval == 0:\n    #    agent.save()\n\n    elapsed_time = time.time() - start_time\n    print(\"\\nTrain time: \", elapsed_time)\n    env.reset()\n    z = agent.view()\n\n    df = pd.DataFrame(z)\n    df.columns = [\"timestep\", \"action\", \"lastmarket\", \"newmarket\", \"reward\"]\n        #df['lastmarket']+=1\n        #df['newmarket']+=1\n        #df['short'] = np.nan\n        #df.loc[df['action']==0, 'short'] = df['newmarket']\n        #df['flat'] = np.nan\n        #df.loc[df['action']==1, 'flat'] = df['newmarket']\n        #df['long'] = np.nan\n        #df.loc[df['action']==2, 'long'] = df['newmarket']\n        #df['totalreward'] = df['reward'].cumsum()\n        #df.to_csv('df_index_list_{}.csv'.format(i))\n    prob=agent.predict_model.predict(agent.state_memory)\n    action = np.random.choice(agent.action_space, p=prob[0])\n    pick_index=np.array(df_index['stock'][index_list[i]])\n        #arr=np.array(df_index['stock'][index_list[i]])\n    mean_diff=np.mean(np.absolute(np.diff(pick_index)))\n    action_arr=np.array(df['action']-1)\n        \n    wap_future_index=[]\n    #assume in the first time index of t+60 the same as t\n    wap_future_index.append(pick_index[0])\n    for j in range(len(action_arr)):\n        wap_future_index.append(action_arr[j]*mean_diff+pick_index[j+1])\n    wap_future_index.append((action-1)*mean_diff+pick_index[-1])\n    seconds_in_bucket=[j * 10 for j in index_list[i]]\n    comb=list(zip(seconds_in_bucket,pick_index,wap_future_index))\n    result_index.append(comb)\n    \nresult_indx_list = list(chain.from_iterable(result_index))\n#print(result_indx_list)\nsorted_indx_result = sorted(result_indx_list, key=lambda x: x[0])\n#print(sorted_indx_result)\nseconds_in_bucket, wap_index, wap_index_future = zip(*sorted_indx_result)\n#seconds_in_bucket_list=list(seconds_in_bucket)\nwap_index_list=list(wap_index)\nwap_index_future_list=list(wap_index_future)\n\ntruth=[]\ncalculation=[]\nfor indx in tqdm(range(int(min(test['stock_id'])),int(max(test['stock_id']))+1)):\n    df_new=Data_input(test,indx,date,amplifier)\n    result=[]\n    for i in range(len(index_list)):\n        ticks_per_episode = len(index_list[i])/dt-1-lag\n        def shm_market_gen():\n            return market_gen(gen=user_sub(df_new,index_list[i],start_trend=amplifier),\n                      lag=1)\n\n        env = Market(shm_market_gen,\n             lag=lag,\n             nstocks=1,\n             episode_length=ticks_per_episode)\n\n        agent = REINFORCE_Agent(state_size=nstocks*lag*2,\n                        action_size=3,\n                       )\n\n        start_time = time.time()\n        print(\"Start: %s\" % (time.strftime(\"%H:%M:%S\")))\n\n        for e in range(N_EPISODES):\n            agent.run_episode()\n            agent.score_episode(e, N_EPISODES)\n    \n\n    #if e and (e+1) % agent.save_interval == 0:\n    #    agent.save()\n\n        elapsed_time = time.time() - start_time\n        print(\"\\nTrain time: \", elapsed_time)\n        env.reset()\n        z = agent.view()\n\n        df = pd.DataFrame(z)\n        df.columns = [\"timestep\", \"action\", \"lastmarket\", \"newmarket\", \"reward\"]\n        prob=agent.predict_model.predict(agent.state_memory)\n        action = np.random.choice(agent.action_space, p=prob[0])\n        pick_index=np.array(df_new['stock'][index_list[i]])\n        mean_diff=np.mean(np.absolute(np.diff(pick_index)))\n        action_arr=np.array(df['action']-1)\n    \n        wap_future_index=[]\n    #assume in the first time index of t+60 the same as t\n        wap_future_index.append(pick_index[0])\n        for j in range(len(action_arr)):\n            wap_future_index.append(action_arr[j]*mean_diff+pick_index[j+1])\n        wap_future_index.append((action-1)*mean_diff+pick_index[-1])\n        seconds_in_bucket=[j * 10 for j in index_list[i]]\n        comb=list(zip(seconds_in_bucket,pick_index,wap_future_index))\n        result.append(comb)\n    result_list = list(chain.from_iterable(result))\n#print(result_list)\n    sorted_result = sorted(result_list, key=lambda x: x[0])\n#print(sorted_result)\n    seconds_in_bucket, wap, wap_future = zip(*sorted_result)\n    seconds_in_bucket_list=list(seconds_in_bucket)\n    wap_list=list(wap)\n    wap_future_list=list(wap_future)\n\n    target_out=[]\n    for i in range(len(seconds_in_bucket_list)):\n        target_out.append((wap_future_list[i]/wap_list[i]-wap_index_future_list[i]/wap_index_list[i])*10000)\n    calculation.extend(target_out)\n\n    data_sub=excelfilereader[excelfilereader['stock_id']==indx]\n    data_sub2=data_sub[data_sub['revealed_date_id']==date]\n    data=pd.DataFrame(data_sub2,columns=['revealed_target'])\n    data = data.values.tolist()\n    data=np.squeeze(data)\n    truth.append(data)\n#print(data)\n\n#plt.plot(data,label=\"truth\")\n#plt.plot(target_out,label=\"Calculated\")\n#plt.ylabel('Target')\n#plt.title('Target of stock {} at date {}'.format(stock,date))\n#plt.legend()\n#plt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-21T01:36:56.828029Z","iopub.execute_input":"2023-11-21T01:36:56.828475Z","iopub.status.idle":"2023-11-21T01:37:28.480469Z","shell.execute_reply.started":"2023-11-21T01:36:56.828439Z","shell.execute_reply":"2023-11-21T01:37:28.477936Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"layer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_117\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\nNone\nStart: 01:36:57\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"01:37:25 episode 500/500:, score: 2.415408000000866, 10-episode avg: 2.5 Memory: 983.2 KB           \nTrain time:  27.96029019355774\nprev mkt: 1.0869 action: 2, new mkt 1.3753, reward 0.288445\nprev mkt: 1.3753 action: 0, new mkt 0.7831, reward 0.592189\nprev mkt: 0.7831 action: 2, new mkt 1.1325, reward 0.349364\nprev mkt: 1.1325 action: 0, new mkt 0.4120, reward 0.720463\nprev mkt: 0.4120 action: 2, new mkt 0.4070, reward -0.005050\nprev mkt: 0.4070 action: 2, new mkt 0.8868, reward 0.479815\nprev mkt: 0.8868 action: 2, new mkt 1.1438, reward 0.256987\nprev mkt: 1.1438 action: 1, new mkt 1.4106, reward 0.000000\n2.6822130000009565\nlayer 1 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nlayer 2 size 16, relu, reg_penalty 0.00000000, dropout 0.000\nModel: \"model_119\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n Input (InputLayer)          [(None, 2)]               0         \n                                                                 \n Dense00 (Dense)             (None, 16)                48        \n                                                                 \n Dense01 (Dense)             (None, 16)                272       \n                                                                 \n Output (Dense)              (None, 3)                 51        \n                                                                 \n=================================================================\nTotal params: 371\nTrainable params: 371\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/optimizers/legacy/adam.py:117: UserWarning:\n\nThe `lr` argument is deprecated, use `learning_rate` instead.\n\n/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:2359: UserWarning:\n\n`Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n\n","output_type":"stream"},{"name":"stdout","text":"None\nStart: 01:37:25\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[58], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (time\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_EPISODES):\n\u001b[0;32m---> 27\u001b[0m     \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     agent\u001b[38;5;241m.\u001b[39mscore_episode(e, N_EPISODES)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#if e and (e+1) % agent.save_interval == 0:\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m#    agent.save()\u001b[39;00m\n","Cell \u001b[0;32mIn[35], line 79\u001b[0m, in \u001b[0;36mAgent.run_episode\u001b[0;34m(self, render)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m render:\n\u001b[1;32m     77\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender()\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[36], line 124\u001b[0m, in \u001b[0;36mREINFORCE_Agent.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m disc_rewards \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(disc_rewards) \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mstd(disc_rewards) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# train states v. actions, (complemented by disc_rewards_std)\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate_memory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisc_rewards\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cost\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/engine/training_v1.py:1181\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_sample_weight_modes(sample_weights\u001b[38;5;241m=\u001b[39msample_weights)\n\u001b[1;32m   1180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_train_function()\n\u001b[0;32m-> 1181\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset_metrics:\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/backend.py:4566\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4560\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[1;32m   4561\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(\n\u001b[1;32m   4562\u001b[0m         tf_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(inputs),\n\u001b[1;32m   4563\u001b[0m         expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   4564\u001b[0m     )\n\u001b[0;32m-> 4566\u001b[0m     session \u001b[38;5;241m=\u001b[39m \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4567\u001b[0m     feed_arrays \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   4568\u001b[0m     array_vals \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/backend.py:786\u001b[0m, in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _MANUAL_VAR_INIT:\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[0;32m--> 786\u001b[0m         \u001b[43m_initialize_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m session\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/backend.py:1252\u001b[0m, in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m   1248\u001b[0m         candidate_vars\u001b[38;5;241m.\u001b[39mappend(v)\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m candidate_vars:\n\u001b[1;32m   1250\u001b[0m     \u001b[38;5;66;03m# This step is expensive, so we only run it on variables not already\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;66;03m# marked as initialized.\u001b[39;00m\n\u001b[0;32m-> 1252\u001b[0m     is_initialized \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_variable_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcandidate_vars\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1255\u001b[0m     \u001b[38;5;66;03m# TODO(kathywu): Some metric variables loaded from SavedModel are never\u001b[39;00m\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;66;03m# actually used, and do not have an initializer.\u001b[39;00m\n\u001b[1;32m   1257\u001b[0m     should_be_initialized \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1258\u001b[0m         (\u001b[38;5;129;01mnot\u001b[39;00m is_initialized[n]) \u001b[38;5;129;01mand\u001b[39;00m v\u001b[38;5;241m.\u001b[39minitializer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m n, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(candidate_vars)\n\u001b[1;32m   1260\u001b[0m     ]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    971\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1191\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1371\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1377\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1380\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py:1360\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1359\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[0;32m-> 1360\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extend_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1361\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m   1362\u001b[0m                                   target_list, run_metadata)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/client/session.py:1401\u001b[0m, in \u001b[0;36mBaseSession._extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_extend_graph\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1400\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39m_session_run_lock():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1401\u001b[0m     \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExtendSession\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error as mae\n\nerror = mae(truth, calculation) \n\nprint(\"Mean absolute error : \" + str(error)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#agent.rlplot(\"Training Progress: stock {} date {}\".format(int(stock),int(date)))","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:53:59.601412Z","iopub.execute_input":"2023-11-21T00:53:59.601924Z","iopub.status.idle":"2023-11-21T00:53:59.608262Z","shell.execute_reply.started":"2023-11-21T00:53:59.601880Z","shell.execute_reply":"2023-11-21T00:53:59.606671Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"#env.reset()\n#z = agent.view()\n\n#df = pd.DataFrame(z)\n#df.columns = [\"timestep\", \"action\", \"lastmarket\", \"newmarket\", \"reward\"]\n#df['lastmarket']+=1\n#df['newmarket']+=1\n#df['short'] = np.nan\n#df.loc[df['action']==0, 'short'] = df['newmarket']\n#df['flat'] = np.nan\n#df.loc[df['action']==1, 'flat'] = df['newmarket']\n#df['long'] = np.nan\n#df.loc[df['action']==2, 'long'] = df['newmarket']\n#df['totalreward'] = df['reward'].cumsum()\n#df.to_csv('df.csv')\n#df","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:53:59.610002Z","iopub.execute_input":"2023-11-21T00:53:59.610444Z","iopub.status.idle":"2023-11-21T00:53:59.624670Z","shell.execute_reply.started":"2023-11-21T00:53:59.610404Z","shell.execute_reply":"2023-11-21T00:53:59.622704Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"#def tradesim_chart(df, title=\"Trading Simulation\"):\n\n#    fig = go.Figure()\n#    markersize=4\n\n    # x axis\n#    x = df['timestep']\n\n#    red = 'rgba(192, 32, 32, 0.75)'\n#    blue = 'rgba(32, 32, 192, 0.75)'\n#    green = 'rgba(0, 204, 0, 0.75)'\n#    black = 'rgba(32, 32, 32, 0.75)'\n\n#    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n\n#    fig.add_trace(go.Scatter(y=df['short'],\n#                             x=x,\n#                             name='Short (left axis)',\n#                             mode='markers',\n#                             marker=dict(size=markersize,\n#                                         color=red),\n#                            ),\n #                 secondary_y=False,\n #                )\n\n  #  fig.add_trace(go.Scatter(y=df['flat'],\n  #                           x=x,\n  #                           name='Flat (left axis)',\n  #                           mode='markers',\n  #                           marker=dict(size=markersize,\n  #                                       color=blue),\n  #                          ),\n  #                secondary_y=False,\n  #               )\n\n  #  fig.add_trace(go.Scatter(y=df['long'],\n#                          x=x,\n#                             name='Long (left axis)',\n#                             mode='markers',\n#                             marker=dict(size=markersize,\n#                                         color=green),\n#                            ),\n#                  secondary_y=False,\n#                 )\n\n #   fig.add_trace(go.Scatter(y=df['totalreward'],\n #                            x=x,\n #                            name='Total reward (right)',\n  #                           mode='markers',\n  #                           marker=dict(size=markersize,\n  #                                       color=black),\n  #                          ),\n  #                secondary_y=True,\n  #               )\n\n    # plot attributes\n  #  fig.update_layout(\n  #      title= dict(text=title,\n  #                  x=0.5,\n  #                  xanchor='center'),\n  #      xaxis=dict(\n  #          title=\"Timesteps\",\n  #          linecolor='black',\n  #          linewidth=1,\n  #          mirror=True\n  #      ),\n  #      yaxis=dict(\n  #          title=\"Price\",\n  #          linecolor='black',\n  #          linewidth=1,\n  #          mirror=True\n  #      ),\n  #      showlegend=True,\n  #      legend=dict(x=0.738, y=0.05)\n  #  )\n\n  #  fig.update_yaxes(title_text=\"Total reward\", secondary_y=True)\n\n  #  fig.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:53:59.628708Z","iopub.execute_input":"2023-11-21T00:53:59.629268Z","iopub.status.idle":"2023-11-21T00:53:59.640968Z","shell.execute_reply.started":"2023-11-21T00:53:59.629223Z","shell.execute_reply":"2023-11-21T00:53:59.639336Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"#tradesim_chart(df, title=\"Trading stock {} date {}\".format(int(stock),int(date)))","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:53:59.643892Z","iopub.execute_input":"2023-11-21T00:53:59.644452Z","iopub.status.idle":"2023-11-21T00:53:59.659909Z","shell.execute_reply.started":"2023-11-21T00:53:59.644410Z","shell.execute_reply":"2023-11-21T00:53:59.658132Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"#prob=agent.predict_model.predict(agent.state_memory)\n#print(prob)\n#action = np.random.choice(agent.action_space, p=prob[0])\n#print(action)\n#action\n#arr=np.array(df_new['stock'][index_pick])\n#mean_diff=np.mean(np.absolute(np.diff(arr)))\n#action_arr=np.array(df['action']-1)\n#print(action_arr)\n#pick=np.array(df_new['stock'][index_pick])\n#wap_future=[]\n#assume the first stock i\n#wap_future.append(pick[0])\n#for i in range(len(action_arr)):\n#    wap_future.append(action_arr[i]*mean_diff+pick[i+1])\n#index=[1,2,3,4,5,6,7,8,9]\n#wap_future.append((action-1)*mean_diff+pick[-1])\n#plt.plot(pick,\"*\",label=\"truth\")\n#plt.plot(index,wap_future,\"*\",label=\"prediction\")\n#plt.legend()\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:53:59.662154Z","iopub.execute_input":"2023-11-21T00:53:59.662846Z","iopub.status.idle":"2023-11-21T00:53:59.674340Z","shell.execute_reply.started":"2023-11-21T00:53:59.662789Z","shell.execute_reply":"2023-11-21T00:53:59.673097Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def shm_market_gen():\n#    return market_gen(gen=user_sub(df_index,index_pick,start_trend=amplifier),\n#                      lag=lag)\n\n#env = Market(shm_market_gen,\n#             lag=lag,\n#             nstocks=1,\n#             episode_length=ticks_per_episode)\n\n#agent = REINFORCE_Agent(state_size=nstocks*lag*2,\n#                        action_size=3,\n#                       )\n#agent.reset()\n#start_time = time.time()\n#print(\"Start: %s\" % (time.strftime(\"%H:%M:%S\")))\n\n#for e in range(N_EPISODES):\n#    agent.run_episode()\n#    agent.score_episode(e, N_EPISODES)\n    \n\n    #if e and (e+1) % agent.save_interval == 0:\n    #    agent.save()\n\n#elapsed_time = time.time() - start_time\n#print(\"\\nTrain time: \", elapsed_time)","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:53:59.676820Z","iopub.execute_input":"2023-11-21T00:53:59.678244Z","iopub.status.idle":"2023-11-21T00:53:59.695134Z","shell.execute_reply.started":"2023-11-21T00:53:59.678183Z","shell.execute_reply":"2023-11-21T00:53:59.693337Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"#agent.rlplot(\"Training Progress: Index date {}\".format(int(date)))","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:53:59.696822Z","iopub.execute_input":"2023-11-21T00:53:59.697221Z","iopub.status.idle":"2023-11-21T00:53:59.710809Z","shell.execute_reply.started":"2023-11-21T00:53:59.697182Z","shell.execute_reply":"2023-11-21T00:53:59.709278Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"#prob=agent.predict_model.predict(agent.state_memory)\n#print(prob)\n#action = np.random.choice(agent.action_space, p=prob[0])\n#print(action)\n#action\n#arr=np.array(df_index['stock'][index_pick])\n#mean_diff=np.mean(np.absolute(np.diff(arr)))\n#print(np.mean(np.absolute(np.diff(arr))))\n#action_arr=np.array(df['action']-1)\n#print(action_arr)\n#pick_index=np.array(df_index['stock'][index_pick])\n#wap_future_index=[]\n#assume in the first time index of t+60 the same as t\n#wap_future_index.append(pick_index[0])\n#for i in range(len(action_arr)):\n#    wap_future_index.append(action_arr[i]*mean_diff+pick_index[i+1])\n#index=[1,2,3,4,5,6,7,8,9]\n#wap_future_index.append((action-1)*mean_diff+pick_index[-1])\n#plt.plot(pick_index,\"*\",label=\"truth\")\n#plt.plot(index,wap_future_index,\"*\",label=\"prediction\")\n#plt.legend()\n#plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:53:59.714331Z","iopub.execute_input":"2023-11-21T00:53:59.714801Z","iopub.status.idle":"2023-11-21T00:53:59.725151Z","shell.execute_reply.started":"2023-11-21T00:53:59.714767Z","shell.execute_reply":"2023-11-21T00:53:59.724194Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"#def target():\n#    target_out=[]\n#    for i in range(len(index_pick)):\n#        target_out.append((wap_future[i]/pick[i]-wap_future_index[i]/pick_index[i])*10000)\n#    return target_out\n\n#seconds_in_bucket=[i * 10 for i in index_pick]\n#comb=list(zip(seconds_in_bucket,target()))\n#print(\"day=\",date,\"Stock=\",stock,\"seconds_in_bucket\", seconds_in_bucket, target())\n#print(comb)        \n#sorted_zipped = sorted(comb, key=lambda x: x[0])    \n#sorted_list1, sorted_list2 = zip(*sorted_zipped)\n#print(list(sorted_list1))\n#print(list(sorted_list2))","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:53:59.728281Z","iopub.execute_input":"2023-11-21T00:53:59.729300Z","iopub.status.idle":"2023-11-21T00:53:59.745481Z","shell.execute_reply.started":"2023-11-21T00:53:59.729261Z","shell.execute_reply":"2023-11-21T00:53:59.743816Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"#env = Market(shm_market_gen,\n#             lag=lag,\n#             nstocks=1,\n#             episode_length=ticks_per_episode)\n#env.reset()","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:53:59.747245Z","iopub.execute_input":"2023-11-21T00:53:59.747772Z","iopub.status.idle":"2023-11-21T00:53:59.757797Z","shell.execute_reply.started":"2023-11-21T00:53:59.747737Z","shell.execute_reply":"2023-11-21T00:53:59.756318Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"#import optiver2023\n#env = optiver2023.make_env()\n#iter_test = env.iter_test()\n#counter = 0\n#for (test, revealed_targets, sample_prediction) in iter_test:\n   \n#            sample_prediction['target']\n            \n#    env.predict(sample_prediction)\n#    counter += 1","metadata":{"execution":{"iopub.status.busy":"2023-11-21T00:53:59.760492Z","iopub.execute_input":"2023-11-21T00:53:59.762049Z","iopub.status.idle":"2023-11-21T00:54:00.462115Z","shell.execute_reply.started":"2023-11-21T00:53:59.761765Z","shell.execute_reply":"2023-11-21T00:54:00.460864Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[52], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (test, revealed_targets, sample_prediction) \u001b[38;5;129;01min\u001b[39;00m iter_test:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m#stock=test['stock_id']\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#date=test['date_id']\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     date_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mmax\u001b[39m(test[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_id\u001b[39m\u001b[38;5;124m'\u001b[39m]]))\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      9\u001b[0m     it\u001b[38;5;241m=\u001b[39m\u001b[38;5;28miter\u001b[39m(date_range)\n\u001b[1;32m     10\u001b[0m     date\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(it)\n","\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'date_id'"],"ename":"ValueError","evalue":"invalid literal for int() with base 10: 'date_id'","output_type":"error"}]}]}